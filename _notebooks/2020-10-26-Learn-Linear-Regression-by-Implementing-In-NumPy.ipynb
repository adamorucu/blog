{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Linear Regression by Implementing in NumPy\n",
    "> Explaination of linear regression by implementing it in Python NumPy.\n",
    "\n",
    "- toc: false \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Adam Orucu\n",
    "- categories: [machine learning, numpy]\n",
    "- image: images/cover/linear-regression.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the principle:\n",
    "> The best way to learn is by doing.\n",
    "\n",
    "In this post we will learn how linear regression works and implement it at the same time. This is the first post of a series so if you end up learning something usefull don't stop and continue with the next ones. The whole post is a _Jupyter Notebook_ and was created using `Fast Pages` so if you'd like to replicate the steps you can do so by using the above links for several different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/adam/.local/lib/python3.8/site-packages (1.18.5)\n",
      "Requirement already satisfied: pandas in /home/adam/.local/lib/python3.8/site-packages (1.0.4)\n",
      "Requirement already satisfied: matplotlib in /home/adam/.local/lib/python3.8/site-packages (3.2.2)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.11.0-py3-none-any.whl (283 kB)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/adam/.local/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/adam/.local/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/adam/.local/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/adam/.local/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/adam/.local/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/adam/.local/lib/python3.8/site-packages (from seaborn) (1.5.1)\n",
      "Requirement already satisfied: scikit-learn in /home/adam/.local/lib/python3.8/site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/adam/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/adam/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=cde406bd7c10f7f3c76bddea3546d6651f4bf293eab80c1cb8ea53d9452ef7a8\n",
      "  Stored in directory: /home/adam/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: seaborn, sklearn\n",
      "Successfully installed seaborn-0.11.0 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip3 install numpy pandas matplotlib seaborn sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Code\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data\n",
    "\n",
    "Data that we will be using to train and test the model is the [Boston Housing Dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html). This dataset contains information on housing in the city of Boston and we will use it to try to predict value of some owner-occupied homes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "X, y = datasets.load_boston(return_X_y=True)\n",
    "X = pd.DataFrame(data=X, columns=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['AGE'].to_numpy().reshape(-1, 1), y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be viewed below. Here every column represents an attribute of the data, like age, crime, or patio-ratio. Although for this project only one attribute will be uses to ease the visualisation - namely **age** of the property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "temp = X; temp['target'] = y; temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Goal\n",
    "As stated our goal is to predict values of given houses to be as close to the real value as possible. Below an example can be viewed, which was created using scikit-learn the table presents predicted and true values for 5 housing units. We will be creating a similar model on our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>21.133509</td>\n",
       "      <td>27.338643</td>\n",
       "      <td>19.351957</td>\n",
       "      <td>30.380613</td>\n",
       "      <td>20.200315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>23.600000</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1          2          3          4\n",
       "Prediction  21.133509  27.338643  19.351957  30.380613  20.200315\n",
       "True        23.600000  32.400000  13.600000  22.800000  16.100000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression as skLinReg\n",
    "clf = skLinReg().fit(X_train, y_train, )\n",
    "pd.DataFrame(data=[clf.predict(X_test)[:5], y_test[:5]], index=['Prediction', 'True'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get to It\n",
    "\n",
    "Although the linear regression model is fairly simple to understand while making predictions, there is some math involved in the process of training the model. So without further ado, let's begin.\n",
    "\n",
    "---\n",
    "\n",
    "Prediction making in linear regression can be basically stated as drawing a line through the available data so that it represents the data as accurately as possible. We do that ofcourse by creating an equation that represents a line, e.g. $3x + 4 = y$. This equation says that if our input data point is a $2$ the prediction made will be $10$. The input data can of course have more then one attribute for a single data point. In such a case the equation can be written as follows; $\\theta_1 * x_1 + \\theta_2 * x_2 + \\theta_0 = y$. Theta, being the weight of each attribute.\n",
    "\n",
    "Since we will not get only one data point but much more, it will be usefull to represent it with a matrix, where each column of $X$ is an attribute, each row a seperate data point that is available to us. Thetas and the output y can represented as two vectors in such a case. This will result in the below equation.\n",
    "$$X \\cdot \\theta = y$$\n",
    "Pretty simple formula right? So, let's code it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output_html .hll { background-color: #ffffcc }\n",
       ".output_html  { background: #f8f8f8; }\n",
       ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".output_html .go { color: #888888 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">predict</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">add_intercept</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">add_intercept</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">column_stack</span><span class=\"p\">((</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">((</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">),</span> <span class=\"n\">X</span><span class=\"p\">))</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">X</span> <span class=\"o\">@</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">Theta</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{def} \\PY{n+nf}{predict}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{X}\\PY{p}{,} \\PY{n}{add\\PYZus{}intercept}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{if} \\PY{n}{add\\PYZus{}intercept}\\PY{p}{:}\n",
       "        \\PY{n}{X} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{column\\PYZus{}stack}\\PY{p}{(}\\PY{p}{(}\\PY{n}{np}\\PY{o}{.}\\PY{n}{ones}\\PY{p}{(}\\PY{p}{(}\\PY{n}{X}\\PY{o}{.}\\PY{n}{shape}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{n}{X}\\PY{o}{.}\\PY{n}{dtype}\\PY{p}{)}\\PY{p}{,} \\PY{n}{X}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{X} \\PY{o}{@} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{Theta}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "\n",
       "def predict(self, X, add_intercept=True):\n",
       "    if add_intercept:\n",
       "        X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
       "    return X @ self.Theta"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "Code('''\n",
    "def predict(self, X, add_intercept=True):\n",
    "    if add_intercept:\n",
    "        X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "    return X @ self.Theta\n",
    "''', language='py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the code-snippet that does exactly what we have said so far. Returns an array of predictions by multiplying each row (data point) with theta (weight). You may have realised the two extra lines here. They add to our matrix a column of 1s which are called the intercept they will help us add the $\\theta_0$ weight.\n",
    "\n",
    "---\n",
    "\n",
    "Now since we now how to make predictions once we have our thetas defined let's learn how we actually choose the thetas that best fir our data. We will see how this can be done, using two different methods. Let's start with **gradient descent**. The general idea here is that; we calculate the error our model is making at step by step try to minimize it.\n",
    "\n",
    "That said let's define our error (loss) function. Since we try to draw a line so that the distance to the data points is as small as possible, our function will do just that; calculate the average distance to the data points. Instead of getting the absoloute value of the distances we will sqaure it. This is done so the values that are a little off will not affect the model very much, but values that will end up being very far away from the line that we drew increase the error even more.\n",
    "$$\\frac{\\sum_{i=0}^n( X_i \\cdot \\theta - y)}{2n}$$\n",
    "You probably see an extra 2 in the denominator, it is just to help us in further calculation, you shouldn't worry about it very much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output_html .hll { background-color: #ffffcc }\n",
       ".output_html  { background: #f8f8f8; }\n",
       ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".output_html .go { color: #888888 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">fit</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">lamb</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">add_intercept</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">iters</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">1e-6</span><span class=\"p\">):</span>\n",
       "    <span class=\"sd\">&quot;&quot;&quot;Fits the training data using gradient descent&quot;&quot;&quot;</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">add_intercept</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">column_stack</span><span class=\"p\">((</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">((</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">),</span> <span class=\"n\">X</span><span class=\"p\">))</span>\n",
       "    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n",
       "    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">X</span>\n",
       "    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">),</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n",
       "    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">Theta</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">loss_prime</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">theta</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">@</span> <span class=\"n\">theta</span> <span class=\"o\">-</span> <span class=\"n\">y</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">T</span> <span class=\"o\">@</span> <span class=\"n\">x</span>\n",
       "    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">theta</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"o\">/</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"o\">*</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">n</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">square</span><span class=\"p\">(</span><span class=\"n\">X</span> <span class=\"o\">@</span> <span class=\"n\">theta</span> <span class=\"o\">-</span> <span class=\"n\">y</span><span class=\"p\">))</span>\n",
       "    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_gradient_descent</span><span class=\"p\">(</span><span class=\"n\">iters</span><span class=\"o\">=</span><span class=\"n\">iters</span><span class=\"p\">,</span> <span class=\"n\">loss_prime</span><span class=\"o\">=</span><span class=\"n\">loss_prime</span><span class=\"p\">,</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"n\">lr</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">loss</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{def} \\PY{n+nf}{fit}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{lamb}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,} \\PY{n}{add\\PYZus{}intercept}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,} \\PY{n}{iters}\\PY{o}{=}\\PY{l+m+mi}{20}\\PY{p}{,} \\PY{n}{lr}\\PY{o}{=}\\PY{l+m+mf}{1e\\PYZhy{}6}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}Fits the training data using gradient descent\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{k}{if} \\PY{n}{add\\PYZus{}intercept}\\PY{p}{:}\n",
       "        \\PY{n}{X} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{column\\PYZus{}stack}\\PY{p}{(}\\PY{p}{(}\\PY{n}{np}\\PY{o}{.}\\PY{n}{ones}\\PY{p}{(}\\PY{p}{(}\\PY{n}{X}\\PY{o}{.}\\PY{n}{shape}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{n}{X}\\PY{o}{.}\\PY{n}{dtype}\\PY{p}{)}\\PY{p}{,} \\PY{n}{X}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{n}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{p} \\PY{o}{=} \\PY{n}{X}\\PY{o}{.}\\PY{n}{shape}\n",
       "    \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{X} \\PY{o}{=} \\PY{n}{X}\n",
       "    \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{y} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{reshape}\\PY{p}{(}\\PY{n}{y}\\PY{p}{,} \\PY{p}{(}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{y}\\PY{p}{)}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{Theta} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{randn}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{p}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "    \\PY{n}{loss\\PYZus{}prime} \\PY{o}{=} \\PY{k}{lambda} \\PY{n}{x}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{theta}\\PY{p}{:} \\PY{p}{(}\\PY{n}{x} \\PY{o}{@} \\PY{n}{theta} \\PY{o}{\\PYZhy{}} \\PY{n}{y}\\PY{p}{)}\\PY{o}{.}\\PY{n}{T} \\PY{o}{@} \\PY{n}{x}\n",
       "    \\PY{n}{loss} \\PY{o}{=} \\PY{k}{lambda} \\PY{n}{x}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{theta}\\PY{p}{:} \\PY{l+m+mi}{1}\\PY{o}{/}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{o}{*}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{n}\\PY{p}{)} \\PY{o}{*} \\PY{n}{np}\\PY{o}{.}\\PY{n}{sum}\\PY{p}{(}\\PY{n}{np}\\PY{o}{.}\\PY{n}{square}\\PY{p}{(}\\PY{n}{X} \\PY{o}{@} \\PY{n}{theta} \\PY{o}{\\PYZhy{}} \\PY{n}{y}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{\\PYZus{}gradient\\PYZus{}descent}\\PY{p}{(}\\PY{n}{iters}\\PY{o}{=}\\PY{n}{iters}\\PY{p}{,} \\PY{n}{loss\\PYZus{}prime}\\PY{o}{=}\\PY{n}{loss\\PYZus{}prime}\\PY{p}{,} \\PY{n}{lr}\\PY{o}{=}\\PY{n}{lr}\\PY{p}{,} \\PY{n}{loss}\\PY{o}{=}\\PY{n}{loss}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "\n",
       "def fit(self, X, y, lamb=0, add_intercept=True, iters=20, lr=1e-6):\n",
       "    \"\"\"Fits the training data using gradient descent\"\"\"\n",
       "    if add_intercept:\n",
       "        X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
       "    self.n, self.p = X.shape\n",
       "    self.X = X\n",
       "    self.y = np.reshape(y, (len(y), 1))\n",
       "    self.Theta = np.random.randn(self.p, 1)\n",
       "    loss_prime = lambda x, y, theta: (x @ theta - y).T @ x\n",
       "    loss = lambda x, y, theta: 1/(2*self.n) * np.sum(np.square(X @ theta - y))\n",
       "    self._gradient_descent(iters=iters, loss_prime=loss_prime, lr=lr, loss=loss)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "Code('''\n",
    "def fit(self, X, y, lamb=0, add_intercept=True, iters=20, lr=1e-6):\n",
    "    \"\"\"Fits the training data using gradient descent\"\"\"\n",
    "    if add_intercept:\n",
    "        X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "    self.n, self.p = X.shape\n",
    "    self.X = X\n",
    "    self.y = np.reshape(y, (len(y), 1))\n",
    "    self.Theta = np.random.randn(self.p, 1)\n",
    "    loss_prime = lambda x, y, theta: (x @ theta - y).T @ x\n",
    "    loss = lambda x, y, theta: 1/(2*self.n) * np.sum(np.square(X @ theta - y))\n",
    "    self._gradient_descent(iters=iters, loss_prime=loss_prime, lr=lr, loss=loss)\n",
    "''', language='py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now our loss function we can move on to the gradient descent. Since we try to minimize the value of the loss function, we can understand what values of thetas make it smaller by calculating the derivate of the loss function we just defined. We is the following:\n",
    "$$(X \\cdot \\theta - y)' \\cdot X$$\n",
    "We can move towards a smaller error by substracting this derivative from the theta that we used to calculate it. And that's the gradient descent algorithm. One addition is that instead of just substracting the derivative we first multiply it by a small number (learning rate) so we don't take too big steps and just little by little go to the right direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output_html .hll { background-color: #ffffcc }\n",
       ".output_html  { background: #f8f8f8; }\n",
       ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".output_html .go { color: #888888 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">gradient_descent</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">iters</span><span class=\"p\">,</span> <span class=\"n\">lr</span><span class=\"p\">):</span>\n",
       "    <span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">hstack</span><span class=\"p\">((</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">((</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">)))</span>\n",
       "    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">),</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n",
       "    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">iters</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">gradient</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weights</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">y</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">transpose</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weights</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weights</span> <span class=\"o\">-</span> <span class=\"p\">(</span><span class=\"n\">lr</span> <span class=\"o\">*</span> <span class=\"mi\">1</span><span class=\"o\">/</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">m</span> <span class=\"o\">*</span> <span class=\"n\">gradient</span><span class=\"o\">.</span><span class=\"n\">transpose</span><span class=\"p\">())</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"o\">/</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"o\">*</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">square</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">weights</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">y</span><span class=\"p\">)))</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{def} \\PY{n+nf}{gradient\\PYZus{}descent}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{iters}\\PY{p}{,} \\PY{n}{lr}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{n}{X} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{hstack}\\PY{p}{(}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{np}\\PY{o}{.}\\PY{n}{ones}\\PY{p}{(}\\PY{p}{(}\\PY{n}{X}\\PY{o}{.}\\PY{n}{shape}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{n}{X}\\PY{o}{.}\\PY{n}{dtype}\\PY{p}{)}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{n}{y} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{reshape}\\PY{p}{(}\\PY{n}{y}\\PY{p}{,} \\PY{p}{(}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{y}\\PY{p}{)}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n}{iters}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{gradient} \\PY{o}{=} \\PY{p}{(}\\PY{n}{X}\\PY{o}{.}\\PY{n}{dot}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weights}\\PY{p}{)} \\PY{o}{\\PYZhy{}} \\PY{n}{y}\\PY{p}{)}\\PY{o}{.}\\PY{n}{transpose}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{dot}\\PY{p}{(}\\PY{n}{X}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weights} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weights} \\PY{o}{\\PYZhy{}} \\PY{p}{(}\\PY{n}{lr} \\PY{o}{*} \\PY{l+m+mi}{1}\\PY{o}{/}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{m} \\PY{o}{*} \\PY{n}{gradient}\\PY{o}{.}\\PY{n}{transpose}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{loss}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{o}{/}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{o}{*}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{m}\\PY{p}{)} \\PY{o}{*} \\PY{n}{np}\\PY{o}{.}\\PY{n}{sum}\\PY{p}{(}\\PY{n}{np}\\PY{o}{.}\\PY{n}{square}\\PY{p}{(}\\PY{n}{X}\\PY{o}{.}\\PY{n}{dot}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{weights}\\PY{p}{)} \\PY{o}{\\PYZhy{}} \\PY{n}{y}\\PY{p}{)}\\PY{p}{)}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "\n",
       "def gradient_descent(self, X, y, iters, lr):\n",
       "    X = np.hstack((X, np.ones((X.shape[0], 1), dtype=X.dtype)))\n",
       "    y = np.reshape(y, (len(y),1))\n",
       "    for i in range(iters):\n",
       "        gradient = (X.dot(self.weights) - y).transpose().dot(X)\n",
       "        self.weights = self.weights - (lr * 1/self.m * gradient.transpose())\n",
       "        self.loss.append(1/(2*self.m) * np.sum(np.square(X.dot(self.weights) - y)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "Code('''\n",
    "def _gradient_descent(self, iters, loss_prime, lr, loss=None):\n",
    "    \"\"\"Gradient descent algorithm\"\"\"\n",
    "    for i in range(iters):\n",
    "        grad = loss_prime(self.X, self.y, self.Theta)\n",
    "        self.Theta -= lr * grad.T\n",
    "        if loss != None:\n",
    "            self.loss.append(loss(self.X, self.y, self.Theta))\n",
    "''', language='py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was all! If you'd like to see what we ended up with click the button below. Now we will move on to testing our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "class LinearRegression:\n",
    "    \"\"\"Linear regression algorithm\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "        \n",
    "    def fit(self, X, y, lamb=0, add_intercept=True, iters=20, lr=1e-6):\n",
    "        \"\"\"Fits the training data using normal equation\"\"\"\n",
    "        if add_intercept:\n",
    "            X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "        self.n, self.p = X.shape\n",
    "        self.X = X\n",
    "        self.y = np.reshape(y, (len(y), 1))\n",
    "        self.Theta = np.random.randn(self.p, 1)\n",
    "        loss_prime = lambda x, y, theta: (x @ theta - y).T @ x\n",
    "        loss = lambda x, y, theta: 1/(2*self.n) * np.sum(np.square(X @ theta - y))\n",
    "        self._gradient_descent(iters=iters, loss_prime=loss_prime, lr=lr, loss=loss)\n",
    "\n",
    "    def predict(self, X, add_intercept=True):\n",
    "        \"\"\"Makes predictions on the given data\"\"\"\n",
    "        if add_intercept:\n",
    "            X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "        return X @ self.Theta\n",
    "    \n",
    "    def _gradient_descent(self, iters, loss_prime, lr, loss=None):\n",
    "        \"\"\"Gradient descent algorithm\"\"\"\n",
    "        for i in range(iters):\n",
    "            grad = loss_prime(self.X, self.y, self.Theta)\n",
    "            self.Theta -= lr * grad.T\n",
    "            if loss != None:\n",
    "                self.loss.append(loss(self.X, self.y, self.Theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "You may have realised that we preset values for learning-rate and the number of iterations for gradient descent they are set to values that work, but I would encourage to play around with them. Anyways if we run our model with those parameters here are the values that we obtain. Maybe not as good as the once obtained by scikit-learn but there still seems to have the correct correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas we ended up with:\n",
      " [[31.32592649]\n",
      " [-0.12119402]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>21.133509</td>\n",
       "      <td>27.338643</td>\n",
       "      <td>19.351957</td>\n",
       "      <td>30.380613</td>\n",
       "      <td>20.200315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>23.600000</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1          2          3          4\n",
       "Prediction  21.133509  27.338643  19.351957  30.380613  20.200315\n",
       "True        23.600000  32.400000  13.600000  22.800000  16.100000"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "LinReg = LinearRegression()\n",
    "LinReg.fit(X_train, y_train)\n",
    "print('Thetas we ended up with:\\n',LinReg.Theta)\n",
    "pd.DataFrame(data=[LinReg.predict(X_test)[:5,0], y_test[:5]], index=['Prediction', 'True'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison\n",
    "Our error (mean squared error) compared to scikit-learn's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our:  186.30890066587702 \n",
      "Sklearns:  64.45241584915276\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('Our: ', mean_squared_error(LinReg.predict(X_test), y_test),\n",
    "      '\\nSklearns: ', mean_squared_error(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning\n",
    "But the most interesting part is to see how our algorithm learns. Below you can see how our error got smaller with every iteration of the gradient descent algortihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD3CAYAAADxJYRbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAR10lEQVR4nO3ccWjU9/3H8Vd656m5Ow1K2sLgBg0c3T9iclD6Twyt6ypjBWeMl6QLFJ2srra2ljQiVGRzahgp22gbaGmCXG1NbPtHO5BRFzFQ/CehQaTV4v2RP0ahqe5YvpeZO3Of3x/DY/nNJuZ7aa5f3s/HX737fL+595uWp3dHbI1zzgkAYMJ91R4AALByiD4AGEL0AcAQog8AhhB9ADAkXO0BFlMqlTQ3F6xfMAqFagI3c6XY2QZ2Do5Vq0J3ff4HH/25OadcbqbaYyxJXV1t4GauFDvbwM7BUV8fv+vzfL0DAIYQfQAwhOgDgCFEHwAMIfoAYAjRBwBDiD4AGEL0AcAQog8AhhB9ADCE6AOAIUQfAAwh+gBgCNEHAEOIPgAYQvQBwBCiDwCGEH0AMIToA4AhRB8ADCH6AGAI0QcAQ4g+ABhC9AHAEKIPAIb4in6pVNKRI0eUTqfV1dWlycnJeecjIyNqbW1VOp3W8PDwvLMbN26opaVF2WzW/9QAAF98Rf/8+fMqFAoaGhrSyy+/rJMnT5bPisWiTpw4oYGBAWUyGQ0NDWlqaqp8duTIEa1Zs2Z5pgcALImv6I+Pj6u5uVmStHnzZl25cqV8ls1mlUgktH79ekUiEaVSKY2NjUmSent71d7ervvvv38ZRgcALFXYz02e5ykWi5Ufh0Ih3b59W+FwWJ7nKR6Pl8+i0ag8z9NHH32kDRs2qLm5WW+99dY9v1YoVKO6ulo/Y1ZNKHRf4GauFDvbwM7B5yv6sVhM+Xy+/LhUKikcDt/1LJ/PKx6PK5PJqKamRpcuXdKXX36pnp4e9ff3q76+fsHXmptzyuVm/IxZNXV1tYGbuVLsbAM7B0d9ffyuz/uKflNTky5cuKCf//znmpiYUDKZLJ81NDRocnJSuVxOtbW1Ghsb0549e7Rt27byNV1dXTp69OiiwQcALC9f0X/iiSf02Wefqb29Xc45HT9+XJ988olmZmaUTqd16NAh7dmzR845tba26oEHHljuuQEAPtQ451y1h1hIsTgXuI9WQf04WAl2toGdg+O7vt7hL2cBgCFEHwAMIfoAYAjRBwBDiD4AGEL0AcAQog8AhhB9ADCE6AOAIUQfAAwh+gBgCNEHAEOIPgAYQvQBwBCiDwCGEH0AMIToA4AhRB8ADCH6AGAI0QcAQ4g+ABhC9AHAEKIPAIYQfQAwhOgDgCFEHwAMIfoAYAjRBwBDiD4AGEL0AcAQog8AhhB9ADAk7OemUqmko0eP6tq1a4pEIjp27Jh+/OMfl89HRkb0xhtvKBwOq7W1Vbt27VKxWNThw4f1j3/8Q4VCQfv27dPWrVuXbREAwOJ8Rf/8+fMqFAoaGhrSxMSETp48qf7+fklSsVjUiRMn9MEHH2jt2rXq6OjQY489ptHRUdXV1emPf/yj/vnPf+qXv/wl0QeAFeYr+uPj42pubpYkbd68WVeuXCmfZbNZJRIJrV+/XpKUSqU0Njambdu26cknnyxfFwqFKpkbAOCDr+h7nqdYLFZ+HAqFdPv2bYXDYXmep3g8Xj6LRqPyPE/RaLR87wsvvKAXX3zxnl4rFKpRXV2tnzGrJhS6L3AzV4qdbWDn4PMV/Vgspnw+X35cKpUUDofvepbP58t/CHz99dd67rnn1NnZqaeeeuqeXmtuzimXm/EzZtXU1dUGbuZKsbMN7Bwc9fXxuz7v67d3mpqaNDo6KkmamJhQMpksnzU0NGhyclK5XE6FQkFjY2NqbGzUt99+q927d6u7u1s7d+7087IAgArVOOfcUm+689s7X331lZxzOn78uL744gvNzMwonU6Xf3vHOafW1lY9/fTTOnbsmM6dO6eHHnqo/HPefvttrVmzZsHXKhbnAvenbFDfGVSCnW1g5+D4rnf6vqK/koh+MLCzDewcHMv69Q4AIJiIPgAYQvQBwBCiDwCGEH0AMIToA4AhRB8ADCH6AGAI0QcAQ4g+ABhC9AHAEKIPAIYQfQAwhOgDgCFEHwAMIfoAYAjRBwBDiD4AGEL0AcAQog8AhhB9ADCE6AOAIUQfAAwh+gBgCNEHAEOIPgAYQvQBwBCiDwCGEH0AMIToA4AhRB8ADPEV/VKppCNHjiidTqurq0uTk5PzzkdGRtTa2qp0Oq3h4eF7ugcA8P3zFf3z58+rUChoaGhIL7/8sk6ePFk+KxaLOnHihAYGBpTJZDQ0NKSpqakF7wEArIywn5vGx8fV3NwsSdq8ebOuXLlSPstms0okElq/fr0kKZVKaWxsTBMTE995DwBgZfiKvud5isVi5cehUEi3b99WOByW53mKx+Pls2g0Ks/zFrxnIaFQjerqav2MWTWh0H2Bm7lS7GwDOwefr+jHYjHl8/ny41KpVI73/z/L5/OKx+ML3rOQuTmnXG7Gz5hVU1dXG7iZK8XONrBzcNTXx+/6vK/v9JuamjQ6OipJmpiYUDKZLJ81NDRocnJSuVxOhUJBY2NjamxsXPAeAMDK8PVO/4knntBnn32m9vZ2Oed0/PhxffLJJ5qZmVE6ndahQ4e0Z88eOefU2tqqBx544K73AABWVo1zzlV7iIUUi3OB+2gV1I+DlWBnG9g5OJb16x0AQDARfQAwhOgDgCFEHwAMIfoAYAjRBwBDiD4AGEL0AcAQog8AhhB9ADCE6AOAIUQfAAwh+gBgCNEHAEOIPgAYQvQBwBCiDwCGEH0AMIToA4AhRB8ADCH6AGAI0QcAQ4g+ABhC9AHAEKIPAIYQfQAwhOgDgCFEHwAMIfoAYAjRBwBDiD4AGEL0AcCQsJ+bbt26pe7ubt24cUPRaFS9vb3asGHDvGuGh4d15swZhcNh7du3T4899pimp6fV3d0tz/NULBZ16NAhNTY2LssiAIDF+Xqn//777yuZTOq9997T9u3b9eabb847n5qaUiaT0ZkzZ/TOO+/otddeU6FQ0ODgoB599FG9++67OnHihH73u98tyxIAgHvj653++Pi4fv3rX0uStmzZ8j/Rv3z5shobGxWJRBSJRJRIJHT16lU988wzikQikqS5uTmtXr26wvEBAEuxaPTPnj2rU6dOzXtu48aNisfjkqRoNKrp6el5557nlc/vXON5ntatWyfpP58Euru7dfjw4UUHDIVqVFdXu/gmPyCh0H2Bm7lS7GwDOwffotFva2tTW1vbvOf279+vfD4vScrn8+WY3xGLxcrnd66584fAtWvXdPDgQb3yyit65JFHFh1wbs4pl5tZfJMfkLq62sDNXCl2toGdg6O+Pn7X5319p9/U1KSLFy9KkkZHR5VKpeadb9q0SePj45qdndX09LSy2aySyaSuX7+uAwcOqK+vTy0tLX5eGgBQAV/f6Xd0dKinp0cdHR1atWqV+vr6JEmDg4NKJBLaunWrurq61NnZKeecXnrpJa1evVp9fX0qFAr6wx/+IOk/nwj6+/uXbxsAwIJqnHOu2kMspFicC9xHq6B+HKwEO9vAzsGxrF/vAACCiegDgCFEHwAMIfoAYAjRBwBDiD4AGEL0AcAQog8AhhB9ADCE6AOAIUQfAAwh+gBgCNEHAEOIPgAYQvQBwBCiDwCGEH0AMIToA4AhRB8ADCH6AGAI0QcAQ4g+ABhC9AHAEKIPAIYQfQAwhOgDgCFEHwAMIfoAYAjRBwBDiD4AGEL0AcAQX9G/deuWnn/+eXV2dmrv3r26efPm/1wzPDysHTt2aNeuXbpw4cK8s2w2q1QqpdnZWX9TAwB88RX9999/X8lkUu+99562b9+uN998c9751NSUMpmMzpw5o3feeUevvfaaCoWCJMnzPPX29ioSiVQ+PQBgSXxFf3x8XM3NzZKkLVu26NKlS/POL1++rMbGRkUiEcXjcSUSCV29elXOOb366qs6ePCg1q5dW/n0AIAlCS92wdmzZ3Xq1Kl5z23cuFHxeFySFI1GNT09Pe/c87zy+Z1rPM/T66+/rpaWFj388MP3PGAoVKO6utp7vv6HIBS6L3AzV4qdbWDn4Fs0+m1tbWpra5v33P79+5XP5yVJ+Xxe69atm3cei8XK53euicfj+vjjj/Xggw/qww8/1NTUlHbv3q3Tp08v+Ppzc0653Mw9L/RDUFdXG7iZK8XONrBzcNTXx+/6/KLRv5umpiZdvHhRmzZt0ujoqFKp1LzzTZs26U9/+pNmZ2dVKBSUzWaVTCb16aeflq95/PHHNTAw4OflAQA++Yp+R0eHenp61NHRoVWrVqmvr0+SNDg4qEQioa1bt6qrq0udnZ1yzumll17S6tWrl3VwAMDS1TjnXLWHWEixOBe4j1ZB/ThYCXa2gZ2D47u+3uEvZwGAIUQfAAwh+gBgCNEHAEOIPgAYQvQBwBCiDwCGEH0AMIToA4AhRB8ADCH6AGAI0QcAQ4g+ABhC9AHAEKIPAIYQfQAwhOgDgCFEHwAMIfoAYAjRBwBDiD4AGEL0AcAQog8AhhB9ADCE6AOAITXOOVftIQAAK4N3+gBgCNEHAEOIPgAYQvQBwBCiDwCGEH0AMIToA4AhRN+nW7du6fnnn1dnZ6f27t2rmzdv/s81w8PD2rFjh3bt2qULFy7MO8tms0qlUpqdnV2pkSvmd+fp6Wk9++yz+tWvfqV0Oq3PP/98pUdfslKppCNHjiidTqurq0uTk5PzzkdGRtTa2qp0Oq3h4eF7uueHzs/OxWJR3d3d6uzs1M6dO/X3v/+9GqP74mffO27cuKGWlhZls9mVHHl5OPgyMDDg/vKXvzjnnPvrX//qfv/73887/+abb9wvfvELNzs76/71r3+V/9k556anp93evXvdo48+6m7durXis/vld+c///nPbnBw0DnnXDabddu3b1/p0Zfsb3/7m+vp6XHOOff555+7Z599tnxWKBTcT3/6U5fL5dzs7KzbsWOH++abbxa8Jwj87PzBBx+4Y8eOOeecu3nzpmtpaanG6L742ffO2W9/+1v3s5/9zF2/fr0qs1eCd/o+jY+Pq7m5WZK0ZcsWXbp0ad755cuX1djYqEgkong8rkQioatXr8o5p1dffVUHDx7U2rVrqzG6b353fuaZZ9Te3i5Jmpub0+rVq1d89qX67103b96sK1eulM+y2awSiYTWr1+vSCSiVCqlsbGxBe8JAj87b9u2TQcOHChfFwqFVnxuv/zsK0m9vb1qb2/X/fffX5W5KxWu9gBBcPbsWZ06dWrecxs3blQ8HpckRaNRTU9Pzzv3PK98fucaz/P0+uuvq6WlRQ8//PD3P3gFlnPndevWSZKmpqbU3d2tw4cPf8/TV87zPMVisfLjUCik27dvKxwOf+eeC90TBH52jkaj5XtfeOEFvfjiiys+t19+9v3oo4+0YcMGNTc366233qrG2BULxn+NVdbW1qa2trZ5z+3fv1/5fF6SlM/ny2G7IxaLlc/vXBOPx/Xxxx/rwQcf1IcffqipqSnt3r1bp0+f/v6XWKLl3FmSrl27poMHD+qVV17RI4888j1PX7n/v0upVCrH+7v2XOieIPCzsyR9/fXXeu6559TZ2amnnnpqZYeugJ99M5mMampqdOnSJX355Zfq6elRf3+/6uvrV3x+v/h6x6empiZdvHhRkjQ6OqpUKjXvfNOmTRofH9fs7Kymp6eVzWaVTCb16aefKpPJKJPJqL6+XgMDA9UY3xe/O1+/fl0HDhxQX1+fWlpaqjH6kjU1NWl0dFSSNDExoWQyWT5raGjQ5OSkcrmcCoWCxsbG1NjYuOA9QeBn52+//Va7d+9Wd3e3du7cWa3RffGz7+nTp/Xuu+8qk8noJz/5iXp7ewMVfIn/y6Zv//73v9XT06OpqSmtWrVKfX19qq+v1+DgoBKJhLZu3arh4WENDQ3JOaff/OY3evLJJ+f9jMcff1znzp0LxHfckv+d9+3bp2vXrulHP/qRpP+8i+rv76/yNgsrlUo6evSovvrqKznndPz4cX3xxReamZlROp3WyMiI3njjDTnn1Nraqqeffvqu9zQ0NFR7lXvmZ+djx47p3Llzeuihh8o/5+2339aaNWuquMm98bPvf+vq6tLRo0cD9e9YIvoAYApf7wCAIUQfAAwh+gBgCNEHAEOIPgAYQvQBwBCiDwCG/B+HDYpNZl6iegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(LinReg.loss);plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the visualisation of the result we obtained and comparison to the result using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD3CAYAAADSftWOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2deXgUVdbG3+rupDt7A4EEBAKBsImgoAmICeoQFhVGxhVmdBQHAkEhgshOQCIBATdmEFBxAddPUXEJAlEIi0QGFUYIEnYISSB7Z+v0Ut8fsZt0uqvXWno5v+fxkdTtrrp1+9Z7b51z7rkMy7IsCIIgCJ9CJnUFCIIgCNch8SYIgvBBSLwJgiB8EBJvgiAIH4TEmyAIwgdRiHERo9EIgyFwglrkciag7tcW1AbUBgC1AeBZGwQFyTnLRBFvg4FFVVW9GJfyCtTq0IC6X1tQG1AbANQGgGdt0L59BGcZmU0IgiB8EBJvgiAIH4TEmyAIwgcRxeZtC4NBj8rKa9Drm6SqgmCUljLgM+uAQhGMNm3aQy6X7OciCMLLkEwNKiuvQaUKRVhYLBiGkaoagiCXy2AwGHk5F8uyqKurQWXlNURHd+TlnARB+D6Sibde3+SXws03DMMgLCwStbVVHp1n5e5T+OJYCYwsIGOA8QNiMW9EL55qSRDukVNQivX7zqNUo0VMhBLpyd0wpm+M1NXiBaHvzSnxvv/++xER0Ryy0rlzZ0ydOhXz5s0DwzBISEhAZmYmZDLXzeck3M7haTut3H0Knx8tMf9tZGH+mwSckIqcglKs2FmIRn3zW2qJRosVOwsBwOcFXIx7c6i4Wq0WALBlyxZs2bIF2dnZyM7ORkZGBj788EOwLIvc3FxeKkMIwxfHSlw6ThBisH7febO4mWjUG7F+33lpKsQjYtybw5n3yZMn0dDQgEmTJkGv12PWrFk4fvw4EhMTAQApKSk4cOAAUlNTOc8hlzNQq0MtjpWWMpDLpQ92uXKlCOvWvYLq6mro9XokJPRCevoMhIWFeXRevu+NYazb0FmMHL5TIwu3z+kIuVwm2Ll9BWoD+21QqtFyHvf1dhPj3hyKt0qlwlNPPYWHHnoI58+fx+TJk8GyrPlVPiwsDBqNxu45bK2wZFmWN6eeu2i1jZgzJwNz5y7GjTf2BwDk5HyDJUvm46WXXnX7vHw6LE2wrPurVGWMbQGXMRBs9RutrKM2AOy3QUyEEiU2RC4mQunz7cbXvdlbYelQvLt37464uDgwDIPu3btDrVbj+PHj5vK6ujpERkY6XRlbfHLyQ3x0cqtH52jNhD7/wCN9Jtr9zMGD+3HzzYPMwg0AY8bchy+++AzLly9BaupoDBlyOw4dOojc3J1YuHApHnjgPsTFdUNcXHfMnDmb1zoLxfgBsRY275bHCUIq0pO7WdiFAUClkCE9uZsg1xPTOSrGvTkU788++wynTp3C0qVLUVpaitraWgwbNgz5+flISkpCXl4ehgwZwluFxOTKlSLccENnq+MdO3bC0aO/IjV1tFXZ1aul2Lx5K6Ki1GJUkRdMTsmW0SaDO0fiwNlKJK7N8zsvP+EbmPqbGIIqtnNUjHtzKN4PPvgg5s+fjwkTJoBhGKxYsQJt2rTB4sWL8fLLLyM+Ph6jRo3yqBKP9JnocJYsBO3bd8CJE8etjl++fAkDB95i/rvlgpuoKLVPCbeJeSN6mUXcn738hG8xpm+MKH3OngNRqOub7k0o85lD8Q4ODsbatWutjm/dyq+ZQwruuGM43n9/M06c+B39+jWbTr7++kuo1W2gUqlQXl4GADh16qT5O+6ERHobUnRkgpASew5EXyWg11uHhoZi1apX8Prra1FTUw293oCePROwdOmLKCq6hOzsF7Bz5w506dJV6qryij92ZIKwhz0Hoq8S0OINADfc0BmrVr1idbxPn354772PrY5v3/69GNUSFH/syARhD7Gdo2Lg+zYAwmXSk7tBpbD86X29IxOEPcb0jcGCkQmIjVCCARAbocSCkQk+bSYM+Jl3ICKml58gvAWxnKNiQeIdoPhbRyaIQIPMJgRBED4IiTdBEIQPQuJNEAThgwS8eG/Z8i5mzkzHs89Ox6xZT+PkyQI8/fQUXLhw3uJzto4RBEFIRUA7LM+dO4sDB/Lwxhtvg2EYFBb+gayspeaNJwiCILwVrxDvqk/KUflRGa/nbDMhGupH2tn/TJu2KC0twbfffoWkpNuRkNAbb775HmbNehoAsH9/Hj755AOsWLHG/J3a2lqsXPkCqqurAQAZGXPQo0dPfP75J9i790fo9XqEh4fjxRdXY9euHfj22+0wGo146qk0rFmTjZtuGoiLFy+gbdu2yMp6CUVFl7FixTIoFArI5XIsWrQM7dt34LUtCN/Bn7cFI/jFK8RbKtRqNVaufBmff/4JNm9+EyqVClOmpAMA9u79Ab/99gteeulVhISEmL/z/vubMXhwIsaPfxCXLl3EihXL8J//vInq6mq8+up6yGQyzJ79NAoKmhNeRUREYOXKlwE0ZzF87bU3EBMTi2nTJqGg4AT++KMAvXv3wTPPzMLRo79Co6kh8Q5QKGEY4QpeId7qR9o5nCULweXLlxAWFoYFCzIBACdPnsBzz81Eu3btcOTIYdTV1UGhsGyis2dP45df/ovc3J0AAI1GA5lMhqCgICxduhAhISG4evUq9Ho9AKBr1zjzd6Oi1IiJac6h3aFDDJqatLjvvr/igw/ew+zZzyAsLBxpadPFuHXCC6GEYYQrBLTD8syZQqxZk23ep7NLl64IDw+HTCbDrFlzkZg4BG+9tcHiO3Fx3fDwwxPx739vwvLlKzFy5GicPl2IvLw9eOGFbDz77PMwGq8/gAwja/Fv642E9+/fi4EDb8Frr72Bu+76Cz744D2B7pbwdihhGOEKXjHzlorhw+/G+fPnMGXKEwgNDYHRyCI9fSY+/fRDAMCTT07G5Mn/xO2332H+zuOPT8LKlcuxffs21NfXYdKkKejcuQtCQkLw1FOPITg4CNHR0Sgru+ZUHfr06YcXXlgMuVwOmUyGZ56ZJci9Et4PJQwjXIFhW+40IBA6ncEqGXlJyQXExsZxfMO3EWIPS19rL9q/0fU2aG3zBpoThvlyAiXqB561gUd7WBIEIQ6UMIxwBRJvgvAiKGEY4SySijfLsjadeIQlIli2AgqKpSb8AcmiTRSKYNTV1ZAwOYBlWdTV1UChCJa6Kn6Bya5cotGCxfVY6pyCUqmrRhAuIdnMu02b9qisvIba2iqpqiAYDMPwOigpFMFo06Y9b+cLZCiWmvAXJBNvuVyB6OiOUl1eUMjD7r1QLDXhLwT0Ih0i8OCKmaZYasLXIPEmAgrafJnwFyhUkAgoKJaa8BdIvImAg2KpCX+AzCYEQRA+CIk3QRCED0LiTRAE4YOQeBMEQfggJN4EQRA+CIk3QRCED0LiTRAE4YM4Jd7l5eUYPnw4zpw5gwsXLmDChAmYOHEiMjMzLfZrJAiCIMTBoXjrdDosWbIEKpUKAJCdnY2MjAx8+OGHYFkWubm5gleSIAj/JaegFGM35SNxbR7Gbsqn9LxO4lC8V61ahUcffRQdOnQAABw/fhyJiYkAgJSUFBw8eFDYGhIE4bdQfnX3sbs8ftu2bWjbti2Sk5OxadMmAJa734SFhUGj0Ti8iFzOQK0O5aG6voFcLguo+7UFtQG1AeC4DTYcuGAzv/qGAxcwYWh3oasnCkL1A7vi/fnnn4NhGPz0008oKCjA3LlzUVFRYS6vq6tDZGSkw4sYDGxA5bemfN7UBgC1AeC4DYqrGzmP+0vbCbV7vF2zyQcffICtW7diy5Yt6Nu3L1atWoWUlBTk5+cDAPLy8nDrrbe6VSmCIAjKr+4+LocKzp07F+vWrcMjjzwCnU6HUaNGCVEvgiACAMqv7j4MK8IOwDqdwW9egZyBXpepDQBqA8C5NsgpKPXr/OpCmU0onzdBEJJC+dXdg8SbIIiAwx9m+yTeBEEEFKbYclOIoim2HIBPCTjlNiEIIqBYv++8zdjy9fvOS1MhNyHxJggioCjVaF067q2QeBMEEVD4S2w5iTdBEAGFv8SWk8OSIIiAwuSUpGgTgiCcxh9C1PwBf4gtJ/EmCJHwlxA1wjsgmzdBiIS/hKgR3gHNvEXCH16X/eEepMRfQtQI74DEWwT84XXZH+5BamIilCixIdS+FqJGeAdkNhEBf3hd9od7kBp/CVEjvAOaeYuAP7wu+8M9SEVLc1OEUg6lQoGaRj2ZngiPIPEWAX94XfaHe5CC1uamGq0BKoUMy+7pTaJNeASZTUTAH16X/eEepIDMTYRQ0MxbBPxhRZc/3IMUkLmJEAoSb5HwhxVd/nAPYkPmJkIoyGxCeC05BaUYuykfiWvzMHZTPnIKSqWuksuQuYkQCpp5E16Jv8SVk7mJEAoSb8Irsefo8zXhI3MTIQRkNiG8EnL0EYR9SLwJr8RfdjshCKEg8Q5AfMERSI4+grAP2bwDDF9xBJKjjyDsQ+IdYPiSI5AcfQTBDYm3wHhbDmyxHIHbj17B6u//8Jr7JsTF2/q9P0LiLSDeaKIQY8VfTkEpVuwqRKPOe+6bEA9v7Pf+CDksBcQbkxKJ4Qhcv++8WbhNSH3fhHh4Y7/3R2jmLSBcpghbM1+xEMMRSDHagQ39/uJA4i0gXCYKoPnVUqpXSKEdgZSMKbCh318cyGwiIPZMEf78Cpme3A2qIIrRDlQoRl8cvF68r8y+gBNxv+Dy1LOo/qoCBo1B6io5jb3ZrT+/Qo7pG4MX/9ofsRFKMABiI5RYMDKBnFUBwpi+MVgwMoF+f4FxaDYxGAxYtGgRzp07B7lcjuzsbLAsi3nz5oFhGCQkJCAzMxMyGf/jAMuyqNxSBgCo3laJ6m2VVp8JGRyGiDFqRI6OQnCCCgzD8F4PT4gN0FfIcQM7ISVOLXU1/BZvD8UzmebU6lBUVdVLXR2/hGFZlrX3gd27dyM3NxfZ2dnIz8/Hu+++C5Zl8eSTTyIpKQlLlixBcnIyUlNTOc+h0xk8+gH113TQ7KqGJqcKmu+rnfqOPFqBiNHNoh6WEgmZSryXjJYdtnXYFND8CunvMxF6aIVrA1t9SsEAYUrv29iY+oFnbdC+fQRnmcOZ94gRI3DnnXcCAK5cuYLo6Gjs2bMHiYmJAICUlBQcOHDArnh7iqJ9ENpMjEabidEWx1k9i/r8WtTkVEGTUwXdpSZzmaFMj6qtZajaWmZ1vrDkCESMViNidBSCuwg7A6Zl3gTf2ArF07NAdaMeAMVVBwpORZsoFArMnTsXu3btwuuvv44ff/zRbJ4ICwuDRqOx+325nIFaHep5bW3Q5t4w3HCvdQdtPN+Iim/KUbG9HNV7LGfrdfs0qNunQcnCSxbHld2UaDu2HdqNa4fIYVFgFI5NMNuPXsHaXadQXN2IjlEqzE7thfHtwi3ud8LQ7pgwtLubd8gftuo6bmAnQa4ll8sE+819BaHawBl/SaPeiA0HLkje76gfCNcGDs0mLbl27Roefvhh1NbW4vDhwwCazSoHDx7EkiVLOL/nqdmET4wNRtTtq0HNjmpodlTBUKZ36nsRo6IQMUaNiJFRUEQHAeA2ibx4f3+vs/eKbb6h12V+26CljZthAKMTTy0D4OfZKbxc312oH0hoNvnyyy9RWlqKtLQ0hISEgGEY9O/fH/n5+UhKSkJeXh6GDBniVsWkQBYiQ8RINSJGqoGX48zHWZaF9lQjNDuqoNlRjYYjdRbf03xfbWVv7wpgUbQSvyTo8UuCAedjjWjUG7F21ymk/CtRjNtxGl9KSOVrCO08bD3wOjvd8neneKDjcOZdX1+P+fPno6ysDHq9HpMnT0aPHj2wePFi6HQ6xMfHIysrC3K5nPMc3jTzdgeDxoDaH5odpjU5VWAbHD89TAiDyDFqRIxRI/zuKMgjuNvHVdwRi8S1ebBVa6FmZ4Ey47L3RjNhaHde2mDspnybEUsyplnII5RyNOiM0LWYjnuLUzxQ+oE9hJp5u2Q2cRdfF28uxm3Ih/K0DoMK5RhUqEDnMuciWjwJb3TX/MElALERSnw9Jcnp6ztLoDy09tp13/N38dIGzgy8tgZ0QHpHeaD0A3tIZjYhuJk2vBtWaAuxraMO21J0AK7bvG8PDeMMb2w4UoeGI3W4mlVkcVwerWierY9WIyw5wmZ4o7vmj/TkbjZFn1a9eYYYeTycWW7eOuUBZfbzf0i8PYArDHDcwE6oqqp3K7yxckuZeWFSS0zhjfrLTUCUdV0ciQWFLAqDGHk83Bl4ycfh/5B4e4irSZ4YBYOwYREIGxaBjlldLMqaLmqbHaM5Vajbbxl+aQpvXAPLkKNrUUb82tOA8wNlYPWs3fBG2pmGf8R4o3Fn4A2UzH7evNJU6LqRzVsA+LbzmcMbc6pQ/k0l5NVGx1+C7fBGsQgkWyfXQyplG4jt4+BCyDbw5tXLfNWNHJYiI/RDaxaLGi1ualRiUn1bdPxFj4ZfnLumso+q2WE6Rg3VwFBB8sEEknhzIWUbeIuwCdkG3jJA2YKvupHD0s9wxvxhqPkzvHGHdXij9mQjtCdLUPZKicV3hAxvJMQlEHwc3mwaEqNuJN5+ijxSjqj72yLq/rYWx1kji8aj9ajZ0eww1Z5svF7WwPps9kbCmpaDvOltLfO7P/xGyL150wcx6kbiHWAwMgYht4Qh5JYwxMy/waLMXvZGT8IbCWnx17BBbw5/TU/uhqydx3AVnyHUkIxgtivvdSObtwD4m73XXnijPcTM3uiNeEs/kNI2LJr/x0tMQ5qmGiw7uATvn9hsPhZiuA0DlCvcqhs5LEXGWx5aMbAX3shFUNfg5lzrY9QITQp3KnujL+It/UDs1Agt8ZY2EJIabTUyDy7EBwXvW5VN6j8Za0avhr7evTdSclgSghHcVYl2kzug3eQOFscjlEpc+bq0eba+oxqG8uvZG3UXm1Cx6SoqNl21Op+U4Y3+ijfbhn2VqsZKLDowD5/+8ZFV2ZQB0zA/aQnCgsIAAOHBoaiq538A83rx9rbXIsI55CHy69kbX7l+3Jy9MacKmh1VVuGNtrI3AuKEN/or3mwb9iUqGsuxYN/z2Fb4f1Zl0wY+g7mJCxEaJF7ucq8Wb6kdLb4wcHhjHXMKSrHhwAUUVzda1YlhGKh6h0DVOwT/HSXD+n015rpPv6UrhhYpKbyRZ/w5bFDo/l/WUIb5ec/hqzPbrMqeueVZzLltPlQKFW/XcwWvtnlL6WjxZJGDWHY+V+sohtA7WydX6m4vvNEe5vDGMWooE8R/wALB3usIX1xhWVpfirl7Z+G7c19blc0aPAfP3vo8lHLnTU4BmVVQzCD81sJW36T3+sQ+riQfcvUtxl2hd7ZOrtSdwhsJW/CZfKukrhhz9mbg+/M5VmVzbpuPmYNmI1ge7FF9+carxVsoR0trYRoW3wbfHr9qIWxceMPqLROuDG5CCr07deJrYHZ3c2q72Rv/FPbgzs4/rLYGO6n3j/R3PO1DRZrLmL13Bn64uNuqbH7iYjx9SwaC5N7rNPdq8U5P7oblO05Z7BASJGM8crTYEqbPj5Y4+NZ1vMlD78rgxofQr/3hjEPxdrZOQkdAeJq9sWSB5ebU9sIbuQa7sFCl1+1l6k+404eqtVVI2zXJpmAvGrIM6Tc/A4XMq2XRjNfXsrVJ3lMTvS1hchZv89C7EkXAh9BXN+qRU1DKy6YPnkZAuGvWsfjeaCXSX7z+vZbZG10Jb6ztY8Rt3WX4racRmj+DDTzdy9QbHdHehrN9qKqxEjvOf4evz3yJXRe+tyhbdvsKTBkwDXKZ7zm6vVq81+87D30rrdaz8Mju7MpreZRKgZAgOecDJPUD5koUAR9Cb7qWvXs0lXFFm7hT99a4a9Zx9D2LzaldCG/sd1KGfieVACwHwsvRRpReK3I5vFHqKCtTHcTu265e014fqmysQM65b/H1mS+Rd3kPdEYdukR0xbSBz2Bop2EY2W00ZIxv+zq8OtrktrV5No97sjKMK4KlNY681mJsPMs3zj4cOQWlWPLdHzbP4Wzbe2MqUCGilww1BixZcATx/2NxS6EcSr1jgXYU3ih1qlM+ozic7Qd8XLO8oRw5577B9jNfYH9RHvRGPbpGdsO4HvdjbPxfcXOHQZKsDwi4aJOcglLOMk/solwz0Htv7IADZyudHvXtOQCFdFRxCbAzwuzsTjpj+sZgTe5p1GgNVmVS2/xzCko5B19Hb1WO7P7uzDblkXLcMT0OK3YWYoP++vlD5DJk9+qJnkcNLmdvHBxuxC8JDIrbWc6rxHKWS7GFmrvXLGsow3dnv8Y7xz7B8cpDAIxQohNGdX0Kzyb9HTdFD/TbBV1eK97r953nLPPE7szXggUpcglzvU4fLaq2ipbx9DX7ub/09LpVeab758LRwGLP7u+JqYKrT907tDuq7qm3Dm+8+md44w7b4Y0PIRgP7bWMdKkJZVHQj4VmQLXg4Y1S9G1Xrnm1/iq+Pbsd35z5Cgeu7IORNSKI7YRI/YMIM9yBILY7Tp+Ro6hHRwxoL6xwS2k69VrxttdRPM1L7M5ejq1/pAilXPSZKdfs5ItjJTC2Mn55OlPyxlV59pzNzgws9uz+ns42XelTig5BODTIgPV15Si9+Xrbjk7ogPr8Whz74Ap0u2rQrvq6QEfWM0j6L4OLfz9tdT53wxu5kCIXiqNrltaV4Js/Bfun4gMwskb0VCcgY9Bs7PqtJ6prO4HBdaEWY02G1L4JrxVve04z03GxGsvWjxQkY6BgYOFQVSlkGBbfBsPX7LHrrHMXrgGttXA7+ryzSLVhMddsxt79OGMbtTcgZXLY+IVaEMb50A+LwdBhvZFTUIrV+86b+3p0NYObC+UYVKhAv4uWNnKu8EZ9rBwdxrVzOXujFLlQbF1ToahEQvdTGPdFJvKLfwILFr3b9MGswc9jbI/70adtXzAMg23782DrzoQ2M0lhXmqJ14q3rR/TFmI0lq0fSWdkraJRbC324XNw4RrQZIxtAZfaPu0O9oSN6/5jI5ROty/XgCTmbNOZh95UT5PzsiyKxe5b9dh9a3P4osl5aQpvPPFRMdgf6xBRf13GFCUGt7I3SvHWZTr3qrzvcK7pI8jlGtThBM4Usujbth/m3DYfY3vcj95t+1h9V6qsiVJvw+a14m2rA7nrqPIUrvPXNOqxe/rt5r/HbsoXdCS252xtOWiYjntTTLqz2BM2IWeEYs42XXnoHX3WFN6Ydf4PlPRv8VkW6FTOIOWCEuMrIlzO3njnGDVGT04UxdmXX3wIU3dNQlHt5eYDcqBzeBc83W8hxva4Hwltetn9vlRZE6VOteu14g1Yz5K4QqiEbixnfyShR2J7M6KBN0R5lX3aXey1oeAzwhZRswyAe2/sIEgbuvLQu933GOBKNItPohsxe7blQiFDjQG1udXmRF9so/jZGw8W7Ufarkkorbe8TqgiDG+Nehcj4kY5fS5X+wVfTkapU+16tXi3RqrGcva6YozEXK/9Utmn+cZRGwpxnzkFpXgh5w8L/wULYPv/SjHwhijer+dKPxai78kj5Yga3xZR4zk2p/5zMZLLm1M7yN6Yd3kP0nY+ifLGcovjUUo1NqZuxt1dR3B+1xHO9gt7ZjnAtYmB1E59r16kYwupQnOcua5QKSp9EXcXJqzcfcpmrpkHBsZi3gj7r8+O4PoNR/znIKob9Ta/48nCGHtt4Eo/FqLvufoc2Qtv5EIerYD2rkZkh67Evs550AXpzGXtVO2wceQ7SOl8p1Pn4guut/colQJavVGQZ1eoRTo+J97eSMsHIUIph1wuQ1W9zqvNF7YyK7qySMkR7nZYoVYXconbvTd2sJuYzJPVvGLn83ZlBS1fkwxW92f2xh1ubE7tQXiju5M4rv08ueBjVWvArbD0FVo/CDVaA1RBLJbd09srRRtwnFnRlVwhfL8Fcdm8SzRah0mx7GEvRt4evhSx46zpgM8QNyaIQdgdEci7IQ9TujwBreH67xdTGYN7L9yLCUV/h+Kw5aIie9kb1Q+3g/rRdgjqHAxGZu0w9SS+2l7ggy1a9kepcxm1hsTbQ2w+CDrn0qdKhTOZFe3l+l7fIv7YBF9hkfYeLk/O72qMPOB5+mFvxVPHuqkPnK37AdeUqwBY9qWukd3wxog3cVtsks1Zp0X2xpwqGCquL3bTXWzCtTXFuLamGEwIA2W8CsEJKih7qqBMUCG4pwpv7nV/8OHyIQTLGbuL7qRekGMLEm8P8SR9qlQ4+5CaPrdy9ymbqzhbw0dYpL34fmfOzzU7cjVGngGweHQvr/z9PMVdxzrLsli29x2sP5HRfKDFx2NDuuO9ezbjlpjBDq/vKHtj47F6GBuNaCpshPaMFo2/1aNme6V5jFgOBcoiZShua0RxOxbF7YwoaWtESdsmsCxrN7yRy8kIwK5jWOoFObYg8fYQT9KnSoWzr44xEUpOByIXfKzqBMCZ1dDe+e3NjlyNkfdnJ7O9CJbWg9+0O+JQr9iL9N2Trc4TZOyK6KbZCGZ7IFahdEq47dFyc+rWGBuNaDqnhfZ0IzZ/WIjwEhax5QyS/ydHSNN1sT75/m/mGfqFKD2+qatEQYgW6BqMtLu6mU1LXL8tl1nEnbcVoc0sdsVbp9NhwYIFKCoqQlNTE6ZNm4aePXti3rx5YBgGCQkJyMzMhEzm23lxPSE9uZtbQiMltnYoao3pYV6aY/veuODDRjymb4xN04yj89ubHZmcTu7GyHubvdMTTPVe+8MZc5RNsJwxJzhr0BtQJ8/Fef2ryN9j+d0gY7c/BdsycyYffd1eG8tUMqj6hkDVNwR9esZdH3xYQF3LIK5Kjn92iEHP2iBoCxtRvrca6qsG/ANyAKEwMizKXruII3HXoPpN2xzeODoKkWPUCE5QgWEYu6Lu6tuKGGYWu+K9fft2qNVqrF69GpWVlRg/fjz69OmDjIwMJCUlYcmSJcjNzUVqaiovlfFFvDl9KhemOuts1Blo9rCbHhyugckWfMbcc5lP6pu4zVGOZkfuxsh7o72TD7Qt2rZaq8e7v7+LiuB/A622bQxFAnY8uhV92vZtjgbSCrOvrLNt3Nr0oeoUjIDmn2YAABloSURBVAce6YbkVgv6Ksu1iK2QIbaCQcdyGTpWyDDgRCMA5vrm1C9esTi3eXPqMWqE3XE9eyPX28qw+DYYuynfasARw8xiN1Swrq4OLMsiPDwclZWVePDBB9HU1IS8vDwwDIPdu3fjwIEDyMzMtHsRo9EIg0HwiETJ2H70ChZ+9TsadS1+2CAZXvxrf4wb2InzO2t3nUJxdSM6RqkwO7UX52c9qRfXNXot3sEZMlW4fLT5332W7IC9n45B84KWTq3OL5fLYDC4t91cy/pnfVeAynqdxXGuth2+Zg+uVDeiNZ2iVNj73J1u18Pd8/LRBkIxfM0eFFXXo1a+AxXB663Kg429Ed2UgSC2CxgAp/7sE672dWfbwNPfrnVft3UuE6EyGbK7xKPPCQYV28uhvejcW0PTbSHYEVuHvZ0boeyixJ2922Pbr0UWbQEA6hAFqhpsrxto2ZbOEBTEvZLV7sw7LCwMAFBbW4sZM2YgIyMDq1atMjsEwsLCoNFo7J0CAGAwsH4d550Sp8aC1ATzTKBjlApTh8UhJU5t875bzzKuVDdi4Ze/o65ey9uo7Oga9uzeH/10zlyP+wfEctq8Y22YD0z3y0eMc0qcGkq5tUmuUWfE6u//sNrcd+qwOJuzo6nD4jyqSzGHEBRXN9o9r9hx3ly0NEd0CA9Cr/j9+KlpOdDKtKw09EM73UwEsZb5x2MilOb7aN3XTbNNrr7u7EIlrvmBozY2nad1X7dHvdGI7IpL+HpJEtou6WhR1nRBi5/fv4SKbyrR45xl3ws+3IBxkGEc/tyoFBUYiRBcjTLilwQDfk3Qo7CzkVO4Acu2dAaP4ryLi4sxffp0TJw4EWPHjsXq1avNZXV1dYiMjHS6Iv5My1dvRw+tGK9Ujq5hz1bfsh6mVY2maBMZA4wf4PlqR2dxxVEk1HJlqRMQeUJOQSle3HkS1/AlKkPexnkD8HOL/SyUhpv+FOxYm9+3ZQrjI0WBrYVCtjBtlGHvN3VnU3GufpVbX4UVkSVofPj6+YJkDCIhQ5dTwLDzwRh0WgF59fXyDtUyjP6vDKP/G2R1vl8S9NgyogmVkSzvqTzsindZWRkmTZqEJUuWYOjQoQCAfv36IT8/H0lJScjLy8OQIUN4q0ygIEYqSWfsv846WueN6CWaWLfGVeEUIveJ1AmI3HGWfnO8CJn71uKS8S0rG7bKcDO6yTLA6jtY3dNNHcNx5HKNeaAWKjmXM4Jrsik7soW789xw9R+u9M/lMKC8J/BbzwaoRjdHI63fdx4lNVp0KmcwqFCBQYVyxBdbmjkGFSrAsMAnT0DcaJMNGzagpqYG69evx/r1zXaxhQsXIisrCy+//DLi4+MxapTz2b+IZsSYyTlzjVgfmFFKLZyAtAmIXHHk6Qw6/PvXV5H983Kr86gMg9FO9zQUbHsAQCOAZfdYmj9M+ehNQUhGFvj2+FVBknM5ElyTSc6Zt1RXY/gB7q0UnRkIWqcovhJtxJVoHb4Zaumb6cDKMeBiEA7EahEF/p8pu+K9aNEiLFq0yOr41q1bea9IICGGIDlzDW8QRkdInbmtZT2kiCxxJF5Nhia89starD6cbfXdEEMi2jalQ4Foq7KYPzewaJ1yWayFKPZ8LgxgDu10ZocjV2L4geYkZ66GBNq6vq2QSxMKBqiUGbE7rtn+3iB2qCAhDGIIkjPX8BZhdIS/pLt1B1szQRY6nGzYgg7rrUN0w423Q62dBjna2D2vrQFazJ1h7PlcIlXXZcmZN0h7/diVPPc5BaVo0NkOn+W6vqlvtjZtNegMVoLO90BI4i0RYgiSM9cIZGH0BUzixaIJVYoPURP0mdVn/trjb1iRvBqTtp51OumSrd/ckVDyuVBpTN8YHC2qthnJVKe9Hsvv7NuhuzH8Jpx1oJpwdP3b1ubZ/J4rSbEcQeJNOIU/rTD0FRr0DWjT8WPk69+2KhsaMxab73kd7ULamY+VagqcOm8sh0/D0bJ5PhYqte5HKjmDxlYLCfTs9Ygnsd4OXYlYsWd2McFlb7eRJNFtSLwJh/jTCkNvH4TqdHXIzn8Bm469YVUWpr8bfZTTMSNlgEsz55bY82nYE0o+7OG2+hEXLU01Yrwd2jMNxUYordqjZXZNk1Cb/h8boeR0lDpK7uYKJN6EQ7wxo5o7eOsgVKurxfKfluCd39+yKvt738ex9PYsRCnVNr5pia2Zc5CMQUiQDBqtwemtvdxJPeAMrsxuxY544hr4TJsxmMQ687s/sCb3NBp0RnNuoJbROYD9QSlS6dneny0h8SYcIqYjS0i8aRDSNNVg6cHF2HLiHauyx/tNQubtLyAi2LUFcEKaGFwJb235dmNabTymb4zT/UWKiCdXTEa28hg5i710ta5C4k04xJdXGLZE6kGoWluFJQcW4KOT1qG2k/pPxqKhyxAeFO7RNYQyMTjrOLS1VN30dsPVj6JUCoQEyXkfcFwxkblqMnKXGo69Ut2BxJtwiC/EgzuDFINQZWMFFu2fh/879bFVWdqAdMxLWoywoDDBru8O9kTPkRjae7vh6kez7+7B+4DDZSI7WlTNuVerqyYjd+Czr5F4Ew7xlXhwR4g1CJU3lGPBvufwxenPretw8wzMTVyIEIX1hgPegCO/gKPf3N7bjZj9iGsQcWevVlf3vQSaF+kwDGORM1/U3CYEYcIf4sGFFI9r9dcwb99sfH3mS6uymYNmY/atc6FSqDy+jtB46hdw9HYjVj9ydrbszL0Ni29jFY+uYIAwpQLVjXqb0SYtt0+TZCcdgvA3+BSP0vpSPL/3WeSc+8aqbNatz2PZ3ZloqHXfuSUFnvoFXHm7ETJs05XZsr0d4k35XlrzVycza47pGyNYamASb4JwgeLaK5izNwM7L+ywKnv+tgWYMWgWguXBAAClQokGSJ/P2xU89Qu0frtpGW3SEqHDNu1tZN0aezvEc+WyP3C20uM6egqJN0E44LLmEmbvmYEfL+ValS1MykT6zTMQJLfO5eyL8OEXcCa3vdBhm7ZMZF3UShy+VGP12WHxbTjrxEWJRovEtXmIVCnAsqzTcfR8QuJNEDa4WHMBz+55Bvsu77EqWzJ0OaYOnA6FzP8eH7GcimKEbdrKmmgL0yzaVackC1gknxJ70Zf/9T6CcJNz1WeR8eN0/HTlgFXZC8NWYPJN0yCX8bdCzlsRw6koRdimowHDXv5vZ2n59rBy9ylBd6Ai8SYCmrNVp/HMD9NwuMR6VpadvBpP9p8MGWO9jybhGXyFbbri9HQ0YPCVd6RUo8XK3acs7OVGFua/+RJwEm8i4CisPIVnctPwy9UjVmUvpbyCx298kgRbYPgwz7jq9HS0BJ6PmTfQbE7hcnR+cayExJsgXKGg/ASezk3D/8qOWpW9cue/MbHvY7zmnSAc40qubVsi76rTk2vAAIAVOwt5zfjHBWUVJAgn+L3sf5i+ewoKKo5blb1+9xt4pPdEEmwvx97s2h2np60Bw53cJaY0saZoE2eTVVE+b4Lg4Ni135C+ezJOVVpvsbV+xJt4IOFhEmwfIaegFEtz/rCarZpm13w5PV2NcJEx1/fYNMG1c05rxg+Idela9iDxJnyeX0uPYOrup3Cu+qxV2Zsj38W4HuNJsH0M04yby8xQqtFi2T29eXF6upq7hGuHHHsmEYo2IYg/OVySj2m7/oWLmgsWxxUyBTamvoOxPf4qUc0IPnC0YCYmQslbTLotR6aCad6OzRa2tpGzJ9yFy0fT8ngisDl05SDSdk1Ccd0Vi+MquQobR76DMd3vlahmBN/YM2XwnZ2v5SBg2taMS7gBoEFnQOLaPIvBQow9K1tD4k14NfuL8pC2cxKuNVgmBwoLCsem1M1I7TZaopoRQsJlypAxwIKRCeZ9JPnKj2L6vDP5UEyrKlteT4w9K1tD4k14HXsv/YgpO59ApdYy+Y9aqcaG1M24u+sIiWpGiAVXTLZJuAH+86O4ktuk9fVi7eyBKRQk3oRX8MPFXZi880lomiwTB0WHRGND6makdL5TmooRkuCMPZvv/Cjufq9Eo8UDA2Px7fGrou42ReJNSMbO8zmYsvNJ1OstnTkxobHYmLoZt99wh0Q1I7wBR4t4+M6PYi/qRMYASoUMDTrbM/Nvj1/FvTd24NxiTQhIvAlR+fbs15iy8wnojDqL453Du+CN1LeR1HGIRDUjfA2+t7WzlwPcyAI6vRFBMsutzUw06o04cLbSKv5bSEi8CcHZfvoLTN75BFhYdvq4yG7YkPo2BsfcJlHNCF+G7/S1raNOWqNngchgGXQcqyn5TGfrDAzLsoKv6NfpDILEOXorQm175CuwLIvvr3yNx7/6h1VZT3UC1o94Ezd3GCRBzcQl0PsB4LttkLg2D7aEkQG3ecW0d2XrwWTC0O5ut0H79hGcZTTzJniBZVn836mP8XRumlVZn7Z98Z+/bMJN7QdKUDOCcB0ugY5UKVDfpLc6rlLIMCy+jc3QxbBQJVLi1LzXkcSbcBuWZfHRya3I+HG6VdmADgPx2p1v4Mbo/hLUjAhU+NrU2Jb9O0jGoE6rt1rAE6VSYPbdPThDF9fuOoWUfyW6dT/2IPEmXIJlWWw58S6e2zvTquzm9rdg3V82onfbPj77ukz4LkIs2mk5ENQ36W1mDwwJkmNM3xhkfmedDA0ArlQ3YuymfN6jT5wS76NHj2LNmjXYsmULLly4gHnz5oFhGCQkJCAzMxMyGSWu92eMrBHv/P4W5u97zqpscMxtWHf3BvRskyBBzQjiOnwv2mkdqpjIkTnQ5Ki0F2ooxP6WDlX3zTffxKJFi6DVNlcqOzsbGRkZ+PDDD8GyLHJzrXfUJnwfI2vEpqPr0WF9JGLfUFsId1LHoTj0919xNb0GOQ/kknATXoHQmxpzxY9HKJv3NU1P7gaVgltSTQMJXzgU765du2LdunXmv48fP47ExGb7TUpKCg4ePMhbZQhpMRgNWP/bOrNgLzowz1x2xw0p+PnvR3E1vQZfj/8e8VE9JKwpQVjDJa6OFu3kFJRi7KZ8JK7Nw9hN+cgpKLX5ufTkblDYSDTVoDMip6AUY/rGYMHIBLtL4vkMJ3RoNhk1ahQuX75s/ptlWXNu5LCwMGg0GocXkcsZqNWhHlTTt5DLZT5zv3qjHi8fWotFexZalaV2T8X6ezYgLirO5fP6UhsIBbWBuG0wZ1RvLPzqdzS2WAWpCpJhzqjenHXYfvQKVuwqNH+nRKPFil3NESLjBnay+OyEod3xyp6zqKy3XGCmM7LYcOACJgztbv5v+Jo9uFLdaHW9jlEq3trDZYdlS/t2XV0dIiMjHX7HYGADynnl7c46nUGHdb++gpU/Z1mVjeg6EmvufA2dwm9oPsDCrXvx9jYQA2oDcdsgJU6NBakJVtEmKXFqzjqs/v4PC7EHgEadEau//8NmeF9VK+E2UVzdaHGNqcPibK7+nDoszqX24DXOu1+/fsjPz0dSUhLy8vIwZAgtZ/YFmgxNeOXIaqz97yqrstHd7sFLw19BbFhHCWpGEPzh7KbGJly1kzubT2VM3xh8/b9iHL50PdHaTR3DxY82acncuXOxePFivPzyy4iPj8eoUaN4qwzBL1qDFmsPr8Krv6yxKrs3fhxWpqxFTKhwiXMIwlP4itvmwtXkVs7mU1m5+5SFcAPA4Us1WLn7FG9bodHyeAGQ8nW5Ud+Ilw6vwL9/fdWq7P6ef8OK5DWIDokWvB5kMqA2ADxrg9Zx24B1Tm9PcecazgwoSS/nce6skz8rxen60fJ4P6deV4/sn5dj49H/WJU9kPAwXkxehbaqdhLUjCDch++4bVu4k9zKGdOMGDvrkHj7KLW6Wqw4tAxv/W+jVdmjff6OF25fAbWqjQQ1Iwh+EDpu24SrdnJnEGNPSxJvH6K2SYNlPy3Be8fftir7R99/YuntWYhURklQM4LgH743WxCT8QNi8fnREpvH+YLE28up0VZj6cFF2FrwnlXZP298CkuGLkNEsONwTYLwNfjebEFMTE7JL46VwMg2z7jHD4jlzVkJkHh7JVWNlVhycAE+PvmBVdm/bkrDgiGZCA8Kl6BmBCEefG+2ICS2nJgDb4gyb4vWIVyJgTfw+1ZM0SYC4I6HvaKxHAv3zcXnhZ9alaUNnI75iYsRGuQ7q/Uo0oLaAAiMNrAVsRIkY8CyrEX6WHciZSjaxEspayjDgn3P4cvT26zKpt88E88nLkCIIkSCmhEE4Sy2omK49rnkM1KGxFtkrtZfxby82fjm7FdWZRmDnsOsW5+HSqGSoGYEQbiDK9EvoiamIjyntK4Ec/ZmYMf576zKZt86F88OnoNgebAENSMIwlPs5fG29Vm+IPEWiCu1RXhuz0zsvrjTqmxu4kLMuGUWguRBEtSMIAg+4doyzZbNm89IGRJvHrmsuYRZe57Bnks/WJUtGrIU6TfPgEJGTU4Q/gRXVIytY3xGylC0iYdcqDmPZ398GvuLrLdIyhyahbSB6QEp2IEQZeAIagNqA8CzNqBoE545W30GM39IR37xT1ZlWcNWYnbys9DU8LuElyAIoiUk3k5yurIQz/wwFUdKD1uVZSevwZP9/wUZ07xRhVwmF7t6BEF4GSt3n6IVllLxR8VJPJObht+u/WpVtnr4q3is3xNmwSYIgjCxcvcpi9wmRhbmv/kScBLvVhSUn8D03Cn4veyYVdmrd/0HE/r8w7yHJ0EQhC2+OGadlMp0nMSbR/5XdgzTd0/GyYoCq7J1d2/Aw70nkGATBOE0lM9bQH67+gvSd0/G6apCq7INqW9jfM8HSbAJgnALyufNM0dKD2Pqrqdwoea8VdlbI9/DuJ7jxa8UQRB+B+Xz5oGfi/MxddckXK69ZHE8SBaEjanv4L4e4ySqGUEQ/ooY+bz9cpHOwaL9SNs1CaX1liNfiCIEG1Pfweju9wh6fVqYQG0AUBsA1AYALdJxyL7Le5G260mUNZRZHI8IjsSm1M34S9xIiWpGEATBPz4t3j9ezEXaridRpa2yON5G2QYbR76DO7vcLVHNCIIghMXnxHv3he8xeeeTqNPVWhyPDmmPjambkdx5uEQ1IwiCEA+fEO8d577DlJ1PoNHQaHG8Y1gnbEh9G0M7DZOoZgRBENLg1eJtMBrQcUMbi2NdIrrijRFvI7FjkkS1IgiCkB6vFm+5TI6He0/Az8WH8EbqWxgcc5vUVSIIgvAKvFq8AeDff9kodRUIgiC8DkqJRxAE4YOQeBMEQfggJN4EQRA+CIk3QRCED0LiTRAE4YOQeBMEQfggJN4EQRA+CIk3QRCEDyJKPm+CIAiCX2jmTRAE4YOQeBMEQfggJN4EQRA+CIk3QRCED0LiTRAE4YOQeBMEQfggJN4EQRA+iNdvxuDt6HQ6LFiwAEVFRWhqasK0adPQs2dPzJs3DwzDICEhAZmZmZDJ/H+cLC8vx9/+9jds3rwZCoUi4Npg48aN+OGHH6DT6TBhwgQkJiYGVBvodDrMmzcPRUVFkMlkWL58eUD1g6NHj2LNmjXYsmULLly4YPO+P/30U3z88cdQKBSYNm0a7rrrLvcvyBIe8dlnn7FZWVksy7JsRUUFO3z4cDYtLY09dOgQy7Isu3jxYnbnzp1SVlEUmpqa2PT0dHbkyJHs6dOnA64NDh06xKalpbEGg4Gtra1lX3/99YBrg127drEzZsxgWZZl9+/fzz799NMB0wabNm1i77vvPvahhx5iWZa1ed9Xr15l77vvPlar1bI1NTXmf7uLfw6BIjJ69GjMnDnT/LdcLsfx48eRmJgIAEhJScHBgwelqp5orFq1Co8++ig6dOgAAAHXBvv370evXr0wffp0TJ06FXfeeWfAtUH37t1hMBhgNBpRW1sLhUIRMG3QtWtXrFu3zvy3rfs+duwYbrnlFgQHByMiIgJdu3bFyZMn3b4mibeHhIWFITw8HLW1tZgxYwYyMjLAsiwYhjGXazQaiWspLNu2bUPbtm2RnJxsPhZobVBZWYnff/8dr732GpYtW4bnnnsu4NogNDQURUVFGDNmDBYvXozHHnssYNpg1KhRUCiuW6Ft3XdtbS0iIiLMnwkLC0Ntba3b1ySbNw8UFxdj+vTpmDhxIsaOHYvVq1eby+rq6hAZGSlh7YTn888/B8Mw+Omnn1BQUIC5c+eioqLCXB4IbaBWqxEfH4/g4GDEx8dDqVSipKTEXB4IbfDuu+/ijjvuwOzZs1FcXIx//vOf0Ol05vJAaAMTLe36pvsODw9HXV2dxfGWYu7yNTyqIYGysjJMmjQJc+bMwYMPPggA6NevH/Lz8wEAeXl5uPXWW6WsouB88MEH2Lp1K7Zs2YK+ffti1apVSElJCag2GDx4MPbt2weWZVFaWoqGhgYMHTo0oNogMjLSLEZRUVHQ6/UB9yyYsHXfAwYMwJEjR6DVaqHRaHDmzBn06tXL7WtQVkEPycrKQk5ODuLj483HFi5ciKysLOh0OsTHxyMrKwtyuVzCWorHY489hqVLl0Imk2Hx4sUB1QYvvfQS8vPzwbIsnn32WXTu3Dmg2qCurg4LFizAtWvXoNPp8Pjjj6N///4B0waXL1/GrFmz8Omnn+LcuXM27/vTTz/FJ598ApZlkZaWhlGjRrl9PRJvgiAIH4TMJgRBED4IiTdBEIQPQuJNEAThg5B4EwRB+CAk3gRBED4IiTdBEIQPQuJNEAThg/w/7pYSxCODb5kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "LinReg = LinearRegression()\n",
    "sk = skLinReg()\n",
    "LinReg.fit(X_train, y_train)\n",
    "sk.fit(X_train, y_train)\n",
    "\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.plot(X_test, LinReg.predict(X_test), 'g')\n",
    "plt.plot(X_test, sk.predict(X_test), 'm')\n",
    "plt.legend(['Our', 'Sklearns'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "#collapse_hide\n",
    "from matplotlib import animation\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "LinReg2 = LinearRegression()\n",
    "LinReg2.fit(X_train, y_train, iters=0)\n",
    "sk = skLinReg()\n",
    "sk.fit(X_train, y_train)\n",
    "ax.scatter(X_test, y_test)\n",
    "ax.plot(X_test, sk.predict(X_test), 'm-')\n",
    "line, = ax.plot(X_test, np.hstack((X_test, np.ones((X_test.shape[0], 1), dtype=X_test.dtype))).dot(LinReg2.Theta), 'r-', linewidth=2)\n",
    "ax.legend(('Sklearns', 'Our'))\n",
    "\n",
    "Writer = animation.writers['pillow']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return line,\n",
    "\n",
    "def animate(i):\n",
    "    LinReg2.fit(X_train, y_train, iters=250)\n",
    "    line.set_data(X_test, LinReg2.predict(X_test))\n",
    "    return line,\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=200, interval=200, repeat_delay=1000, blit=True)\n",
    "\n",
    "anim.save('gif/linreg.gif', writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](gif/linreg.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I had said that we will see two algorithm to find values for theta. The first one was gradient descent. The second is called the normal equation. This equation is possible because linear regression is a quite simple idea, so smart people have found a formula that makes the learning process unnecessary and just gives you the correct answer. If you interested in the proof; do go online, I will not do it here. Anyways, here is the equation:\n",
    "$$(X' \\cdot X)^{-1} \\cdot X' \\cdot y$$\n",
    "Obviously this equation will not work for every situation. Since you need to invert a matrix you may end up with matricees of data where it is not possible to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output_html .hll { background-color: #ffffcc }\n",
       ".output_html  { background: #f8f8f8; }\n",
       ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".output_html .go { color: #888888 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">fit</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">lamb</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">add_intercept</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">iters</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">3e-8</span><span class=\"p\">):</span>\n",
       "    <span class=\"sd\">&quot;&quot;&quot;Fits the training data using normal equation&quot;&quot;&quot;</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">add_intercept</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">column_stack</span><span class=\"p\">((</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">((</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">),</span> <span class=\"n\">X</span><span class=\"p\">))</span>\n",
       "    <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n",
       "    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">X</span>\n",
       "    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">),</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n",
       "    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">Theta</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">linalg</span><span class=\"o\">.</span><span class=\"n\">inv</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">T</span> <span class=\"o\">@</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">X</span><span class=\"p\">)</span> <span class=\"o\">@</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">T</span> <span class=\"o\">@</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">y</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{def} \\PY{n+nf}{fit}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{lamb}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,} \\PY{n}{add\\PYZus{}intercept}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,} \\PY{n}{iters}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{lr}\\PY{o}{=}\\PY{l+m+mf}{3e\\PYZhy{}8}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}Fits the training data using normal equation\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{k}{if} \\PY{n}{add\\PYZus{}intercept}\\PY{p}{:}\n",
       "        \\PY{n}{X} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{column\\PYZus{}stack}\\PY{p}{(}\\PY{p}{(}\\PY{n}{np}\\PY{o}{.}\\PY{n}{ones}\\PY{p}{(}\\PY{p}{(}\\PY{n}{X}\\PY{o}{.}\\PY{n}{shape}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{n}{X}\\PY{o}{.}\\PY{n}{dtype}\\PY{p}{)}\\PY{p}{,} \\PY{n}{X}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{n}{n}\\PY{p}{,} \\PY{n}{p} \\PY{o}{=} \\PY{n}{X}\\PY{o}{.}\\PY{n}{shape}\n",
       "    \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{X} \\PY{o}{=} \\PY{n}{X}\n",
       "    \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{y} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{reshape}\\PY{p}{(}\\PY{n}{y}\\PY{p}{,} \\PY{p}{(}\\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{y}\\PY{p}{)}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{Theta} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{linalg}\\PY{o}{.}\\PY{n}{inv}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{X}\\PY{o}{.}\\PY{n}{T} \\PY{o}{@} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{X}\\PY{p}{)} \\PY{o}{@} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{X}\\PY{o}{.}\\PY{n}{T} \\PY{o}{@} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{y}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "\n",
       "def fit(self, X, y, lamb=0, add_intercept=True, iters=100, lr=3e-8):\n",
       "    \"\"\"Fits the training data using normal equation\"\"\"\n",
       "    if add_intercept:\n",
       "        X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
       "    n, p = X.shape\n",
       "    self.X = X\n",
       "    self.y = np.reshape(y, (len(y), 1))\n",
       "    self.Theta = np.linalg.inv(self.X.T @ self.X) @ self.X.T @ self.y"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C\n",
    "ode('''\n",
    "def fit(self, X, y, lamb=0, add_intercept=True, iters=100, lr=3e-8):\n",
    "    \"\"\"Fits the training data using normal equation\"\"\"\n",
    "    if add_intercept:\n",
    "        X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "    n, p = X.shape\n",
    "    self.X = X\n",
    "    self.y = np.reshape(y, (len(y), 1))\n",
    "    self.Theta = np.linalg.inv(self.X.T @ self.X) @ self.X.T @ self.y\n",
    "''', language='py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see using this equation we ended up with the same error, so with the same theta (weight) that scikit-learn has found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our:  64.45241584915267 \n",
      "Sklearns:  64.45241584915276\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "class LinearRegression:\n",
    "    \"\"\"Linear regression algorithm\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "        \n",
    "    def fit(self, X, y, lamb=0, add_intercept=True, iters=100, lr=3e-8):\n",
    "        \"\"\"Fits the training data using normal equation\"\"\"\n",
    "        if add_intercept:\n",
    "            X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "        n, p = X.shape\n",
    "        self.X = X\n",
    "        self.y = np.reshape(y, (len(y), 1))\n",
    "        self.Theta = np.linalg.inv(self.X.T @ self.X) @ self.X.T @ self.y\n",
    "\n",
    "    def predict(self, X, add_intercept=True):\n",
    "        \"\"\"Makes predictions on the given data\"\"\"\n",
    "        if add_intercept:\n",
    "            X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "        return X @ self.Theta\n",
    "    \n",
    "    def _gradient_descent(self, iters, loss_prime, lr, loss=None):\n",
    "        \"\"\"Gradient descent algorithm\"\"\"\n",
    "        for i in range(iters):\n",
    "            grad = loss_prime(self.X, self.y, self.Theta)\n",
    "            self.Theta -= lr * grad.T\n",
    "            if loss != None:\n",
    "                self.loss.append(loss(self.X, self.y, self.Theta))\n",
    "                \n",
    "LinReg = LinearRegression()\n",
    "LinReg.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('Our: ', mean_squared_error(LinReg.predict(X_test), y_test),\n",
    "      '\\nSklearns: ', mean_squared_error(clf.predict(X_test), y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
