<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Learn Linear Regression by Implementing in NumPy | Adam’s Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Learn Linear Regression by Implementing in NumPy" />
<meta name="author" content="Adam Orucu" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Explaination of linear regression by implementing it in Python NumPy." />
<meta property="og:description" content="Explaination of linear regression by implementing it in Python NumPy." />
<link rel="canonical" href="https://posterrieri.github.io/blog/machine%20learning/numpy/2020/10/26/Learn-Linear-Regression-by-Implementing-In-NumPy.html" />
<meta property="og:url" content="https://posterrieri.github.io/blog/machine%20learning/numpy/2020/10/26/Learn-Linear-Regression-by-Implementing-In-NumPy.html" />
<meta property="og:site_name" content="Adam’s Blog" />
<meta property="og:image" content="https://posterrieri.github.io/blog/images/cover/linear-regression.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-26T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Explaination of linear regression by implementing it in Python NumPy.","url":"https://posterrieri.github.io/blog/machine%20learning/numpy/2020/10/26/Learn-Linear-Regression-by-Implementing-In-NumPy.html","@type":"BlogPosting","headline":"Learn Linear Regression by Implementing in NumPy","dateModified":"2020-10-26T00:00:00-05:00","datePublished":"2020-10-26T00:00:00-05:00","author":{"@type":"Person","name":"Adam Orucu"},"image":"https://posterrieri.github.io/blog/images/cover/linear-regression.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://posterrieri.github.io/blog/machine%20learning/numpy/2020/10/26/Learn-Linear-Regression-by-Implementing-In-NumPy.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://posterrieri.github.io/blog/feed.xml" title="Adam's Blog" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Adam&#39;s Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Learn Linear Regression by Implementing in NumPy</h1><p class="page-description">Explaination of linear regression by implementing it in Python NumPy.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-26T00:00:00-05:00" itemprop="datePublished">
        Oct 26, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Adam Orucu</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      10 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#machine learning">machine learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#numpy">numpy</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/posterrieri/blog/tree/master/_notebooks/2020-10-26-Learn-Linear-Regression-by-Implementing-In-NumPy.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/posterrieri/blog/master?filepath=_notebooks%2F2020-10-26-Learn-Linear-Regression-by-Implementing-In-NumPy.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/posterrieri/blog/blob/master/_notebooks/2020-10-26-Learn-Linear-Regression-by-Implementing-In-NumPy.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-10-26-Learn-Linear-Regression-by-Implementing-In-NumPy.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Following the principle:</p>
<blockquote><p>The best way to learn is by doing.</p>
</blockquote>
<p>In this post we will learn how linear regression works and implement it at the same time. This is the first post of a series so if you end up learning something usefull don't stop and continue with the next ones. The whole post is a <em>Jupyter Notebook</em> and was created using <code>Fast Pages</code> so if you'd like to replicate the steps you can do so by using the above links for several different methods.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Code</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="About-the-data">About the data<a class="anchor-link" href="#About-the-data"> </a></h2><p>Data that we will be using to train and test the model is the <a href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html">Boston Housing Dataset</a>. This dataset contains information on housing in the city of Boston and we will use it to try to predict value of some owner-occupied homes.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_boston</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CRIM&#39;</span><span class="p">,</span> <span class="s1">&#39;ZN&#39;</span><span class="p">,</span> <span class="s1">&#39;INDUS&#39;</span><span class="p">,</span> <span class="s1">&#39;CHAS&#39;</span><span class="p">,</span> <span class="s1">&#39;NOX&#39;</span><span class="p">,</span> <span class="s1">&#39;RM&#39;</span><span class="p">,</span> <span class="s1">&#39;AGE&#39;</span><span class="p">,</span> <span class="s1">&#39;DIS&#39;</span><span class="p">,</span> <span class="s1">&#39;RAD&#39;</span><span class="p">,</span> <span class="s1">&#39;TAX&#39;</span><span class="p">,</span> <span class="s1">&#39;PTRATIO&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;LSTAT&#39;</span><span class="p">])</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="s1">&#39;AGE&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The data can be viewed below. Here every column represents an attribute of the data, like age, crime, or patio-ratio. Although for this project only one attribute will be uses to ease the visualisation - namely <strong>age</strong> of the property.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">temp</span> <span class="o">=</span> <span class="n">X</span><span class="p">;</span> <span class="n">temp</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">;</span> <span class="n">temp</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Our-Goal">Our Goal<a class="anchor-link" href="#Our-Goal"> </a></h2><p>As stated our goal is to predict values of given houses to be as close to the real value as possible. Below an example can be viewed, which was created using scikit-learn the table presents predicted and true values for 5 housing units. We will be creating a similar model on our own.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span> <span class="k">as</span> <span class="n">skLinReg</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">skLinReg</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">y_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">]],</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Prediction&#39;</span><span class="p">,</span> <span class="s1">&#39;True&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Prediction</th>
      <td>21.133509</td>
      <td>27.338643</td>
      <td>19.351957</td>
      <td>30.380613</td>
      <td>20.200315</td>
    </tr>
    <tr>
      <th>True</th>
      <td>23.600000</td>
      <td>32.400000</td>
      <td>13.600000</td>
      <td>22.800000</td>
      <td>16.100000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Let's-Get-to-It">Let's Get to It<a class="anchor-link" href="#Let's-Get-to-It"> </a></h2><p>Although the linear regression model is fairly simple to understand while making predictions, there is some math involved in the process of training the model. So without further ado, let's begin.</p>
<hr />
<p>Prediction making in linear regression can be basically stated as drawing a line through the available data so that it represents the data as accurately as possible. We do that ofcourse by creating an equation that represents a line, e.g. $3x + 4 = y$. This equation says that if our input data point is a $2$ the prediction made will be $10$. The input data can of course have more then one attribute for a single data point. In such a case the equation can be written as follows; $\theta_1 * x_1 + \theta_2 * x_2 + \theta_0 = y$. Theta, being the weight of each attribute.</p>
<p>Since we will not get only one data point but much more, it will be usefull to represent it with a matrix, where each column of $X$ is an attribute, each row a seperate data point that is available to us. Thetas and the output y can represented as two vectors in such a case. This will result in the below equation.

$$X \cdot \theta = y$$

Pretty simple formula right? So, let's code it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<style>.output_html .hll { background-color: #ffffcc }
.output_html  { background: #f8f8f8; }
.output_html .c { color: #408080; font-style: italic } /* Comment */
.output_html .err { border: 1px solid #FF0000 } /* Error */
.output_html .k { color: #008000; font-weight: bold } /* Keyword */
.output_html .o { color: #666666 } /* Operator */
.output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.output_html .cp { color: #BC7A00 } /* Comment.Preproc */
.output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */
.output_html .cs { color: #408080; font-style: italic } /* Comment.Special */
.output_html .gd { color: #A00000 } /* Generic.Deleted */
.output_html .ge { font-style: italic } /* Generic.Emph */
.output_html .gr { color: #FF0000 } /* Generic.Error */
.output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.output_html .gi { color: #00A000 } /* Generic.Inserted */
.output_html .go { color: #888888 } /* Generic.Output */
.output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.output_html .gs { font-weight: bold } /* Generic.Strong */
.output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.output_html .gt { color: #0044DD } /* Generic.Traceback */
.output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.output_html .kp { color: #008000 } /* Keyword.Pseudo */
.output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.output_html .kt { color: #B00040 } /* Keyword.Type */
.output_html .m { color: #666666 } /* Literal.Number */
.output_html .s { color: #BA2121 } /* Literal.String */
.output_html .na { color: #7D9029 } /* Name.Attribute */
.output_html .nb { color: #008000 } /* Name.Builtin */
.output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.output_html .no { color: #880000 } /* Name.Constant */
.output_html .nd { color: #AA22FF } /* Name.Decorator */
.output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */
.output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.output_html .nf { color: #0000FF } /* Name.Function */
.output_html .nl { color: #A0A000 } /* Name.Label */
.output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */
.output_html .nv { color: #19177C } /* Name.Variable */
.output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.output_html .w { color: #bbbbbb } /* Text.Whitespace */
.output_html .mb { color: #666666 } /* Literal.Number.Bin */
.output_html .mf { color: #666666 } /* Literal.Number.Float */
.output_html .mh { color: #666666 } /* Literal.Number.Hex */
.output_html .mi { color: #666666 } /* Literal.Number.Integer */
.output_html .mo { color: #666666 } /* Literal.Number.Oct */
.output_html .sa { color: #BA2121 } /* Literal.String.Affix */
.output_html .sb { color: #BA2121 } /* Literal.String.Backtick */
.output_html .sc { color: #BA2121 } /* Literal.String.Char */
.output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */
.output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.output_html .s2 { color: #BA2121 } /* Literal.String.Double */
.output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */
.output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.output_html .sx { color: #008000 } /* Literal.String.Other */
.output_html .sr { color: #BB6688 } /* Literal.String.Regex */
.output_html .s1 { color: #BA2121 } /* Literal.String.Single */
.output_html .ss { color: #19177C } /* Literal.String.Symbol */
.output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */
.output_html .fm { color: #0000FF } /* Name.Function.Magic */
.output_html .vc { color: #19177C } /* Name.Variable.Class */
.output_html .vg { color: #19177C } /* Name.Variable.Global */
.output_html .vi { color: #19177C } /* Name.Variable.Instance */
.output_html .vm { color: #19177C } /* Name.Variable.Magic */
.output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">add_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Above is the code-snippet that does exactly what we have said so far. Returns an array of predictions by multiplying each row (data point) with theta (weight). You may have realised the two extra lines here. They add to our matrix a column of 1s which are called the intercept they will help us add the $\theta_0$ weight.</p>
<hr />
<p>Now since we now how to make predictions once we have our thetas defined let's learn how we actually choose the thetas that best fir our data. We will see how this can be done, using two different methods. Let's start with <strong>gradient descent</strong>. The general idea here is that; we calculate the error our model is making at step by step try to minimize it.</p>
<p>That said let's define our error (loss) function. Since we try to draw a line so that the distance to the data points is as small as possible, our function will do just that; calculate the average distance to the data points. Instead of getting the absoloute value of the distances we will sqaure it. This is done so the values that are a little off will not affect the model very much, but values that will end up being very far away from the line that we drew increase the error even more.

$$\frac{\sum_{i=0}^n( X_i \cdot \theta - y)}{2n}$$

You probably see an extra 2 in the denominator, it is just to help us in further calculation, you shouldn't worry about it very much.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<style>.output_html .hll { background-color: #ffffcc }
.output_html  { background: #f8f8f8; }
.output_html .c { color: #408080; font-style: italic } /* Comment */
.output_html .err { border: 1px solid #FF0000 } /* Error */
.output_html .k { color: #008000; font-weight: bold } /* Keyword */
.output_html .o { color: #666666 } /* Operator */
.output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.output_html .cp { color: #BC7A00 } /* Comment.Preproc */
.output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */
.output_html .cs { color: #408080; font-style: italic } /* Comment.Special */
.output_html .gd { color: #A00000 } /* Generic.Deleted */
.output_html .ge { font-style: italic } /* Generic.Emph */
.output_html .gr { color: #FF0000 } /* Generic.Error */
.output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.output_html .gi { color: #00A000 } /* Generic.Inserted */
.output_html .go { color: #888888 } /* Generic.Output */
.output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.output_html .gs { font-weight: bold } /* Generic.Strong */
.output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.output_html .gt { color: #0044DD } /* Generic.Traceback */
.output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.output_html .kp { color: #008000 } /* Keyword.Pseudo */
.output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.output_html .kt { color: #B00040 } /* Keyword.Type */
.output_html .m { color: #666666 } /* Literal.Number */
.output_html .s { color: #BA2121 } /* Literal.String */
.output_html .na { color: #7D9029 } /* Name.Attribute */
.output_html .nb { color: #008000 } /* Name.Builtin */
.output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.output_html .no { color: #880000 } /* Name.Constant */
.output_html .nd { color: #AA22FF } /* Name.Decorator */
.output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */
.output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.output_html .nf { color: #0000FF } /* Name.Function */
.output_html .nl { color: #A0A000 } /* Name.Label */
.output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */
.output_html .nv { color: #19177C } /* Name.Variable */
.output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.output_html .w { color: #bbbbbb } /* Text.Whitespace */
.output_html .mb { color: #666666 } /* Literal.Number.Bin */
.output_html .mf { color: #666666 } /* Literal.Number.Float */
.output_html .mh { color: #666666 } /* Literal.Number.Hex */
.output_html .mi { color: #666666 } /* Literal.Number.Integer */
.output_html .mo { color: #666666 } /* Literal.Number.Oct */
.output_html .sa { color: #BA2121 } /* Literal.String.Affix */
.output_html .sb { color: #BA2121 } /* Literal.String.Backtick */
.output_html .sc { color: #BA2121 } /* Literal.String.Char */
.output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */
.output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.output_html .s2 { color: #BA2121 } /* Literal.String.Double */
.output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */
.output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.output_html .sx { color: #008000 } /* Literal.String.Other */
.output_html .sr { color: #BB6688 } /* Literal.String.Regex */
.output_html .s1 { color: #BA2121 } /* Literal.String.Single */
.output_html .ss { color: #19177C } /* Literal.String.Symbol */
.output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */
.output_html .fm { color: #0000FF } /* Name.Function.Magic */
.output_html .vc { color: #19177C } /* Name.Variable.Class */
.output_html .vg { color: #19177C } /* Name.Variable.Global */
.output_html .vi { color: #19177C } /* Name.Variable.Instance */
.output_html .vm { color: #19177C } /* Name.Variable.Magic */
.output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">add_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fits the training data using gradient descent&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">loss_prime</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">x</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_descent</span><span class="p">(</span><span class="n">iters</span><span class="o">=</span><span class="n">iters</span><span class="p">,</span> <span class="n">loss_prime</span><span class="o">=</span><span class="n">loss_prime</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since we now our loss function we can move on to the gradient descent. Since we try to minimize the value of the loss function, we can understand what values of thetas make it smaller by calculating the derivate of the loss function we just defined. We is the following:

$$(X \cdot \theta - y)' \cdot X$$

We can move towards a smaller error by substracting this derivative from the theta that we used to calculate it. And that's the gradient descent algorithm. One addition is that instead of just substracting the derivative we first multiply it by a small number (learning rate) so we don't take too big steps and just little by little go to the right direction.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<style>.output_html .hll { background-color: #ffffcc }
.output_html  { background: #f8f8f8; }
.output_html .c { color: #408080; font-style: italic } /* Comment */
.output_html .err { border: 1px solid #FF0000 } /* Error */
.output_html .k { color: #008000; font-weight: bold } /* Keyword */
.output_html .o { color: #666666 } /* Operator */
.output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.output_html .cp { color: #BC7A00 } /* Comment.Preproc */
.output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */
.output_html .cs { color: #408080; font-style: italic } /* Comment.Special */
.output_html .gd { color: #A00000 } /* Generic.Deleted */
.output_html .ge { font-style: italic } /* Generic.Emph */
.output_html .gr { color: #FF0000 } /* Generic.Error */
.output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.output_html .gi { color: #00A000 } /* Generic.Inserted */
.output_html .go { color: #888888 } /* Generic.Output */
.output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.output_html .gs { font-weight: bold } /* Generic.Strong */
.output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.output_html .gt { color: #0044DD } /* Generic.Traceback */
.output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.output_html .kp { color: #008000 } /* Keyword.Pseudo */
.output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.output_html .kt { color: #B00040 } /* Keyword.Type */
.output_html .m { color: #666666 } /* Literal.Number */
.output_html .s { color: #BA2121 } /* Literal.String */
.output_html .na { color: #7D9029 } /* Name.Attribute */
.output_html .nb { color: #008000 } /* Name.Builtin */
.output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.output_html .no { color: #880000 } /* Name.Constant */
.output_html .nd { color: #AA22FF } /* Name.Decorator */
.output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */
.output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.output_html .nf { color: #0000FF } /* Name.Function */
.output_html .nl { color: #A0A000 } /* Name.Label */
.output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */
.output_html .nv { color: #19177C } /* Name.Variable */
.output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.output_html .w { color: #bbbbbb } /* Text.Whitespace */
.output_html .mb { color: #666666 } /* Literal.Number.Bin */
.output_html .mf { color: #666666 } /* Literal.Number.Float */
.output_html .mh { color: #666666 } /* Literal.Number.Hex */
.output_html .mi { color: #666666 } /* Literal.Number.Integer */
.output_html .mo { color: #666666 } /* Literal.Number.Oct */
.output_html .sa { color: #BA2121 } /* Literal.String.Affix */
.output_html .sb { color: #BA2121 } /* Literal.String.Backtick */
.output_html .sc { color: #BA2121 } /* Literal.String.Char */
.output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */
.output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.output_html .s2 { color: #BA2121 } /* Literal.String.Double */
.output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */
.output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.output_html .sx { color: #008000 } /* Literal.String.Other */
.output_html .sr { color: #BB6688 } /* Literal.String.Regex */
.output_html .s1 { color: #BA2121 } /* Literal.String.Single */
.output_html .ss { color: #19177C } /* Literal.String.Symbol */
.output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */
.output_html .fm { color: #0000FF } /* Name.Function.Magic */
.output_html .vc { color: #19177C } /* Name.Variable.Class */
.output_html .vg { color: #19177C } /* Name.Variable.Global */
.output_html .vi { color: #19177C } /* Name.Variable.Instance */
.output_html .vm { color: #19177C } /* Name.Variable.Magic */
.output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">iters</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">-</span> <span class="p">(</span><span class="n">lr</span> <span class="o">*</span> <span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">*</span> <span class="n">gradient</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span><span class="p">)))</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That was all! If you'd like to see what we ended up with click the button below. Now we will move on to testing our model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Linear regression algorithm&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">add_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fits the training data using normal equation&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">loss_prime</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">x</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_descent</span><span class="p">(</span><span class="n">iters</span><span class="o">=</span><span class="n">iters</span><span class="p">,</span> <span class="n">loss_prime</span><span class="o">=</span><span class="n">loss_prime</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">add_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Makes predictions on the given data&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span>
    
    <span class="k">def</span> <span class="nf">_gradient_descent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iters</span><span class="p">,</span> <span class="n">loss_prime</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gradient descent algorithm&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">loss_prime</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span><span class="o">.</span><span class="n">T</span>
            <span class="k">if</span> <span class="n">loss</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Results">Results<a class="anchor-link" href="#Results"> </a></h4><p>You may have realised that we preset values for learning-rate and the number of iterations for gradient descent they are set to values that work, but I would encourage to play around with them. Anyways if we run our model with those parameters here are the values that we obtain. Maybe not as good as the once obtained by scikit-learn but there still seems to have the correct correlation.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LinReg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">LinReg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Thetas we ended up with:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">LinReg</span><span class="o">.</span><span class="n">Theta</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">LinReg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">]],</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Prediction&#39;</span><span class="p">,</span> <span class="s1">&#39;True&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Thetas we ended up with:
 [[31.32592649]
 [-0.12119402]]
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Prediction</th>
      <td>21.133509</td>
      <td>27.338643</td>
      <td>19.351957</td>
      <td>30.380613</td>
      <td>20.200315</td>
    </tr>
    <tr>
      <th>True</th>
      <td>23.600000</td>
      <td>32.400000</td>
      <td>13.600000</td>
      <td>22.800000</td>
      <td>16.100000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Comparison">Comparison<a class="anchor-link" href="#Comparison"> </a></h5><p>Our error (mean squared error) compared to scikit-learn's.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Our: &#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">LinReg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">),</span>
      <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Sklearns: &#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Our:  186.30890066587702 
Sklearns:  64.45241584915276
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Learning">Learning<a class="anchor-link" href="#Learning"> </a></h4><p>But the most interesting part is to see how our algorithm learns. Below you can see how our error got smaller with every iteration of the gradient descent algortihm.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">LinReg</span><span class="o">.</span><span class="n">loss</span><span class="p">);</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And here is the visualisation of the result we obtained and comparison to the result using sklearn.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LinReg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">sk</span> <span class="o">=</span> <span class="n">skLinReg</span><span class="p">()</span>
<span class="n">LinReg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">sk</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">LinReg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">sk</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="s1">&#39;m&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Our&#39;</span><span class="p">,</span> <span class="s1">&#39;Sklearns&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAW8AAAD3CAYAAADSftWOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2deXgUVdbG3+rupDt7A4EEBAKBsImgoAmICeoQFhVGxhVmdBQHAkEhgshOQCIBATdmEFBxAddPUXEJAlEIi0QGFUYIEnYISSB7Z+v0Ut8fsZt0uqvXWno5v+fxkdTtrrp1+9Z7b51z7rkMy7IsCIIgCJ9CJnUFCIIgCNch8SYIgvBBSLwJgiB8EBJvgiAIH4TEmyAIwgdRiHERo9EIgyFwglrkciag7tcW1AbUBgC1AeBZGwQFyTnLRBFvg4FFVVW9GJfyCtTq0IC6X1tQG1AbANQGgGdt0L59BGcZmU0IgiB8EBJvgiAIH4TEmyAIwgcRxeZtC4NBj8rKa9Drm6SqgmCUljLgM+uAQhGMNm3aQy6X7OciCMLLkEwNKiuvQaUKRVhYLBiGkaoagiCXy2AwGHk5F8uyqKurQWXlNURHd+TlnARB+D6Sibde3+SXws03DMMgLCwStbVVHp1n5e5T+OJYCYwsIGOA8QNiMW9EL55qSRDukVNQivX7zqNUo0VMhBLpyd0wpm+M1NXiBaHvzSnxvv/++xER0Ryy0rlzZ0ydOhXz5s0DwzBISEhAZmYmZDLXzeck3M7haTut3H0Knx8tMf9tZGH+mwSckIqcglKs2FmIRn3zW2qJRosVOwsBwOcFXIx7c6i4Wq0WALBlyxZs2bIF2dnZyM7ORkZGBj788EOwLIvc3FxeKkMIwxfHSlw6ThBisH7febO4mWjUG7F+33lpKsQjYtybw5n3yZMn0dDQgEmTJkGv12PWrFk4fvw4EhMTAQApKSk4cOAAUlNTOc8hlzNQq0MtjpWWMpDLpQ92uXKlCOvWvYLq6mro9XokJPRCevoMhIWFeXRevu+NYazb0FmMHL5TIwu3z+kIuVwm2Ll9BWoD+21QqtFyHvf1dhPj3hyKt0qlwlNPPYWHHnoI58+fx+TJk8GyrPlVPiwsDBqNxu45bK2wZFmWN6eeu2i1jZgzJwNz5y7GjTf2BwDk5HyDJUvm46WXXnX7vHw6LE2wrPurVGWMbQGXMRBs9RutrKM2AOy3QUyEEiU2RC4mQunz7cbXvdlbYelQvLt37464uDgwDIPu3btDrVbj+PHj5vK6ujpERkY6XRlbfHLyQ3x0cqtH52jNhD7/wCN9Jtr9zMGD+3HzzYPMwg0AY8bchy+++AzLly9BaupoDBlyOw4dOojc3J1YuHApHnjgPsTFdUNcXHfMnDmb1zoLxfgBsRY275bHCUIq0pO7WdiFAUClkCE9uZsg1xPTOSrGvTkU788++wynTp3C0qVLUVpaitraWgwbNgz5+flISkpCXl4ehgwZwluFxOTKlSLccENnq+MdO3bC0aO/IjV1tFXZ1aul2Lx5K6Ki1GJUkRdMTsmW0SaDO0fiwNlKJK7N8zsvP+EbmPqbGIIqtnNUjHtzKN4PPvgg5s+fjwkTJoBhGKxYsQJt2rTB4sWL8fLLLyM+Ph6jRo3yqBKP9JnocJYsBO3bd8CJE8etjl++fAkDB95i/rvlgpuoKLVPCbeJeSN6mUXcn738hG8xpm+MKH3OngNRqOub7k0o85lD8Q4ODsbatWutjm/dyq+ZQwruuGM43n9/M06c+B39+jWbTr7++kuo1W2gUqlQXl4GADh16qT5O+6ERHobUnRkgpASew5EXyWg11uHhoZi1apX8Prra1FTUw293oCePROwdOmLKCq6hOzsF7Bz5w506dJV6qryij92ZIKwhz0Hoq8S0OINADfc0BmrVr1idbxPn354772PrY5v3/69GNUSFH/syARhD7Gdo2Lg+zYAwmXSk7tBpbD86X29IxOEPcb0jcGCkQmIjVCCARAbocSCkQk+bSYM+Jl3ICKml58gvAWxnKNiQeIdoPhbRyaIQIPMJgRBED4IiTdBEIQPQuJNEAThgwS8eG/Z8i5mzkzHs89Ox6xZT+PkyQI8/fQUXLhw3uJzto4RBEFIRUA7LM+dO4sDB/Lwxhtvg2EYFBb+gayspeaNJwiCILwVrxDvqk/KUflRGa/nbDMhGupH2tn/TJu2KC0twbfffoWkpNuRkNAbb775HmbNehoAsH9/Hj755AOsWLHG/J3a2lqsXPkCqqurAQAZGXPQo0dPfP75J9i790fo9XqEh4fjxRdXY9euHfj22+0wGo146qk0rFmTjZtuGoiLFy+gbdu2yMp6CUVFl7FixTIoFArI5XIsWrQM7dt34LUtCN/Bn7cFI/jFK8RbKtRqNVaufBmff/4JNm9+EyqVClOmpAMA9u79Ab/99gteeulVhISEmL/z/vubMXhwIsaPfxCXLl3EihXL8J//vInq6mq8+up6yGQyzJ79NAoKmhNeRUREYOXKlwE0ZzF87bU3EBMTi2nTJqGg4AT++KMAvXv3wTPPzMLRo79Co6kh8Q5QKGEY4QpeId7qR9o5nCULweXLlxAWFoYFCzIBACdPnsBzz81Eu3btcOTIYdTV1UGhsGyis2dP45df/ovc3J0AAI1GA5lMhqCgICxduhAhISG4evUq9Ho9AKBr1zjzd6Oi1IiJac6h3aFDDJqatLjvvr/igw/ew+zZzyAsLBxpadPFuHXCC6GEYYQrBLTD8syZQqxZk23ep7NLl64IDw+HTCbDrFlzkZg4BG+9tcHiO3Fx3fDwwxPx739vwvLlKzFy5GicPl2IvLw9eOGFbDz77PMwGq8/gAwja/Fv642E9+/fi4EDb8Frr72Bu+76Cz744D2B7pbwdihhGOEKXjHzlorhw+/G+fPnMGXKEwgNDYHRyCI9fSY+/fRDAMCTT07G5Mn/xO2332H+zuOPT8LKlcuxffs21NfXYdKkKejcuQtCQkLw1FOPITg4CNHR0Sgru+ZUHfr06YcXXlgMuVwOmUyGZ56ZJci9Et4PJQwjXIFhW+40IBA6ncEqGXlJyQXExsZxfMO3EWIPS19rL9q/0fU2aG3zBpoThvlyAiXqB561gUd7WBIEIQ6UMIxwBRJvgvAiKGEY4SySijfLsjadeIQlIli2AgqKpSb8AcmiTRSKYNTV1ZAwOYBlWdTV1UChCJa6Kn6Bya5cotGCxfVY6pyCUqmrRhAuIdnMu02b9qisvIba2iqpqiAYDMPwOigpFMFo06Y9b+cLZCiWmvAXJBNvuVyB6OiOUl1eUMjD7r1QLDXhLwT0Ih0i8OCKmaZYasLXIPEmAgrafJnwFyhUkAgoKJaa8BdIvImAg2KpCX+AzCYEQRA+CIk3QRCED0LiTRAE4YOQeBMEQfggJN4EQRA+CIk3QRCED0LiTRAE4YM4Jd7l5eUYPnw4zpw5gwsXLmDChAmYOHEiMjMzLfZrJAiCIMTBoXjrdDosWbIEKpUKAJCdnY2MjAx8+OGHYFkWubm5gleSIAj/JaegFGM35SNxbR7Gbsqn9LxO4lC8V61ahUcffRQdOnQAABw/fhyJiYkAgJSUFBw8eFDYGhIE4bdQfnX3sbs8ftu2bWjbti2Sk5OxadMmAJa734SFhUGj0Ti8iFzOQK0O5aG6voFcLguo+7UFtQG1AeC4DTYcuGAzv/qGAxcwYWh3oasnCkL1A7vi/fnnn4NhGPz0008oKCjA3LlzUVFRYS6vq6tDZGSkw4sYDGxA5bemfN7UBgC1AeC4DYqrGzmP+0vbCbV7vF2zyQcffICtW7diy5Yt6Nu3L1atWoWUlBTk5+cDAPLy8nDrrbe6VSmCIAjKr+4+LocKzp07F+vWrcMjjzwCnU6HUaNGCVEvgiACAMqv7j4MK8IOwDqdwW9egZyBXpepDQBqA8C5NsgpKPXr/OpCmU0onzdBEJJC+dXdg8SbIIiAwx9m+yTeBEEEFKbYclOIoim2HIBPCTjlNiEIIqBYv++8zdjy9fvOS1MhNyHxJggioCjVaF067q2QeBMEEVD4S2w5iTdBEAGFv8SWk8OSIIiAwuSUpGgTgiCcxh9C1PwBf4gtJ/EmCJHwlxA1wjsgmzdBiIS/hKgR3gHNvEXCH16X/eEepMRfQtQI74DEWwT84XXZH+5BamIilCixIdS+FqJGeAdkNhEBf3hd9od7kBp/CVEjvAOaeYuAP7wu+8M9SEVLc1OEUg6lQoGaRj2ZngiPIPEWAX94XfaHe5CC1uamGq0BKoUMy+7pTaJNeASZTUTAH16X/eEepIDMTYRQ0MxbBPxhRZc/3IMUkLmJEAoSb5HwhxVd/nAPYkPmJkIoyGxCeC05BaUYuykfiWvzMHZTPnIKSqWuksuQuYkQCpp5E16Jv8SVk7mJEAoSb8Irsefo8zXhI3MTIQRkNiG8EnL0EYR9SLwJr8RfdjshCKEg8Q5AfMERSI4+grAP2bwDDF9xBJKjjyDsQ+IdYPiSI5AcfQTBDYm3wHhbDmyxHIHbj17B6u//8Jr7JsTF2/q9P0LiLSDeaKIQY8VfTkEpVuwqRKPOe+6bEA9v7Pf+CDksBcQbkxKJ4Qhcv++8WbhNSH3fhHh4Y7/3R2jmLSBcpghbM1+xEMMRSDHagQ39/uJA4i0gXCYKoPnVUqpXSKEdgZSMKbCh318cyGwiIPZMEf78Cpme3A2qIIrRDlQoRl8cvF68r8y+gBNxv+Dy1LOo/qoCBo1B6io5jb3ZrT+/Qo7pG4MX/9ofsRFKMABiI5RYMDKBnFUBwpi+MVgwMoF+f4FxaDYxGAxYtGgRzp07B7lcjuzsbLAsi3nz5oFhGCQkJCAzMxMyGf/jAMuyqNxSBgCo3laJ6m2VVp8JGRyGiDFqRI6OQnCCCgzD8F4PT4gN0FfIcQM7ISVOLXU1/BZvD8UzmebU6lBUVdVLXR2/hGFZlrX3gd27dyM3NxfZ2dnIz8/Hu+++C5Zl8eSTTyIpKQlLlixBcnIyUlNTOc+h0xk8+gH113TQ7KqGJqcKmu+rnfqOPFqBiNHNoh6WEgmZSryXjJYdtnXYFND8CunvMxF6aIVrA1t9SsEAYUrv29iY+oFnbdC+fQRnmcOZ94gRI3DnnXcCAK5cuYLo6Gjs2bMHiYmJAICUlBQcOHDArnh7iqJ9ENpMjEabidEWx1k9i/r8WtTkVEGTUwXdpSZzmaFMj6qtZajaWmZ1vrDkCESMViNidBSCuwg7A6Zl3gTf2ArF07NAdaMeAMVVBwpORZsoFArMnTsXu3btwuuvv44ff/zRbJ4ICwuDRqOx+325nIFaHep5bW3Q5t4w3HCvdQdtPN+Iim/KUbG9HNV7LGfrdfs0qNunQcnCSxbHld2UaDu2HdqNa4fIYVFgFI5NMNuPXsHaXadQXN2IjlEqzE7thfHtwi3ud8LQ7pgwtLubd8gftuo6bmAnQa4ll8sE+819BaHawBl/SaPeiA0HLkje76gfCNcGDs0mLbl27Roefvhh1NbW4vDhwwCazSoHDx7EkiVLOL/nqdmET4wNRtTtq0HNjmpodlTBUKZ36nsRo6IQMUaNiJFRUEQHAeA2ibx4f3+vs/eKbb6h12V+26CljZthAKMTTy0D4OfZKbxc312oH0hoNvnyyy9RWlqKtLQ0hISEgGEY9O/fH/n5+UhKSkJeXh6GDBniVsWkQBYiQ8RINSJGqoGX48zHWZaF9lQjNDuqoNlRjYYjdRbf03xfbWVv7wpgUbQSvyTo8UuCAedjjWjUG7F21ymk/CtRjNtxGl9KSOVrCO08bD3wOjvd8neneKDjcOZdX1+P+fPno6ysDHq9HpMnT0aPHj2wePFi6HQ6xMfHIysrC3K5nPMc3jTzdgeDxoDaH5odpjU5VWAbHD89TAiDyDFqRIxRI/zuKMgjuNvHVdwRi8S1ebBVa6FmZ4Ey47L3RjNhaHde2mDspnybEUsyplnII5RyNOiM0LWYjnuLUzxQ+oE9hJp5u2Q2cRdfF28uxm3Ih/K0DoMK5RhUqEDnMuciWjwJb3TX/MElALERSnw9Jcnp6ztLoDy09tp13/N38dIGzgy8tgZ0QHpHeaD0A3tIZjYhuJk2vBtWaAuxraMO21J0AK7bvG8PDeMMb2w4UoeGI3W4mlVkcVwerWierY9WIyw5wmZ4o7vmj/TkbjZFn1a9eYYYeTycWW7eOuUBZfbzf0i8PYArDHDcwE6oqqp3K7yxckuZeWFSS0zhjfrLTUCUdV0ciQWFLAqDGHk83Bl4ycfh/5B4e4irSZ4YBYOwYREIGxaBjlldLMqaLmqbHaM5Vajbbxl+aQpvXAPLkKNrUUb82tOA8wNlYPWs3fBG2pmGf8R4o3Fn4A2UzH7evNJU6LqRzVsA+LbzmcMbc6pQ/k0l5NVGx1+C7fBGsQgkWyfXQyplG4jt4+BCyDbw5tXLfNWNHJYiI/RDaxaLGi1ualRiUn1bdPxFj4ZfnLumso+q2WE6Rg3VwFBB8sEEknhzIWUbeIuwCdkG3jJA2YKvupHD0s9wxvxhqPkzvHGHdXij9mQjtCdLUPZKicV3hAxvJMQlEHwc3mwaEqNuJN5+ijxSjqj72yLq/rYWx1kji8aj9ajZ0eww1Z5svF7WwPps9kbCmpaDvOltLfO7P/xGyL150wcx6kbiHWAwMgYht4Qh5JYwxMy/waLMXvZGT8IbCWnx17BBbw5/TU/uhqydx3AVnyHUkIxgtivvdSObtwD4m73XXnijPcTM3uiNeEs/kNI2LJr/x0tMQ5qmGiw7uATvn9hsPhZiuA0DlCvcqhs5LEXGWx5aMbAX3shFUNfg5lzrY9QITQp3KnujL+It/UDs1Agt8ZY2EJIabTUyDy7EBwXvW5VN6j8Za0avhr7evTdSclgSghHcVYl2kzug3eQOFscjlEpc+bq0eba+oxqG8uvZG3UXm1Cx6SoqNl21Op+U4Y3+ijfbhn2VqsZKLDowD5/+8ZFV2ZQB0zA/aQnCgsIAAOHBoaiq538A83rx9rbXIsI55CHy69kbX7l+3Jy9MacKmh1VVuGNtrI3AuKEN/or3mwb9iUqGsuxYN/z2Fb4f1Zl0wY+g7mJCxEaJF7ucq8Wb6kdLb4wcHhjHXMKSrHhwAUUVzda1YlhGKh6h0DVOwT/HSXD+n015rpPv6UrhhYpKbyRZ/w5bFDo/l/WUIb5ec/hqzPbrMqeueVZzLltPlQKFW/XcwWvtnlL6WjxZJGDWHY+V+sohtA7WydX6m4vvNEe5vDGMWooE8R/wALB3usIX1xhWVpfirl7Z+G7c19blc0aPAfP3vo8lHLnTU4BmVVQzCD81sJW36T3+sQ+riQfcvUtxl2hd7ZOrtSdwhsJW/CZfKukrhhz9mbg+/M5VmVzbpuPmYNmI1ge7FF9+carxVsoR0trYRoW3wbfHr9qIWxceMPqLROuDG5CCr07deJrYHZ3c2q72Rv/FPbgzs4/rLYGO6n3j/R3PO1DRZrLmL13Bn64uNuqbH7iYjx9SwaC5N7rNPdq8U5P7oblO05Z7BASJGM8crTYEqbPj5Y4+NZ1vMlD78rgxofQr/3hjEPxdrZOQkdAeJq9sWSB5ebU9sIbuQa7sFCl1+1l6k+404eqtVVI2zXJpmAvGrIM6Tc/A4XMq2XRjNfXsrVJ3lMTvS1hchZv89C7EkXAh9BXN+qRU1DKy6YPnkZAuGvWsfjeaCXSX7z+vZbZG10Jb6ztY8Rt3WX4racRmj+DDTzdy9QbHdHehrN9qKqxEjvOf4evz3yJXRe+tyhbdvsKTBkwDXKZ7zm6vVq81+87D30rrdaz8Mju7MpreZRKgZAgOecDJPUD5koUAR9Cb7qWvXs0lXFFm7hT99a4a9Zx9D2LzaldCG/sd1KGfieVACwHwsvRRpReK3I5vFHqKCtTHcTu265e014fqmysQM65b/H1mS+Rd3kPdEYdukR0xbSBz2Bop2EY2W00ZIxv+zq8OtrktrV5No97sjKMK4KlNY681mJsPMs3zj4cOQWlWPLdHzbP4Wzbe2MqUCGilww1BixZcATx/2NxS6EcSr1jgXYU3ih1qlM+ozic7Qd8XLO8oRw5577B9jNfYH9RHvRGPbpGdsO4HvdjbPxfcXOHQZKsDwi4aJOcglLOMk/solwz0Htv7IADZyudHvXtOQCFdFRxCbAzwuzsTjpj+sZgTe5p1GgNVmVS2/xzCko5B19Hb1WO7P7uzDblkXLcMT0OK3YWYoP++vlD5DJk9+qJnkcNLmdvHBxuxC8JDIrbWc6rxHKWS7GFmrvXLGsow3dnv8Y7xz7B8cpDAIxQohNGdX0Kzyb9HTdFD/TbBV1eK97r953nLPPE7szXggUpcglzvU4fLaq2ipbx9DX7ub/09LpVeab758LRwGLP7u+JqYKrT907tDuq7qm3Dm+8+md44w7b4Y0PIRgP7bWMdKkJZVHQj4VmQLXg4Y1S9G1Xrnm1/iq+Pbsd35z5Cgeu7IORNSKI7YRI/YMIM9yBILY7Tp+Ro6hHRwxoL6xwS2k69VrxttdRPM1L7M5ejq1/pAilXPSZKdfs5ItjJTC2Mn55OlPyxlV59pzNzgws9uz+ns42XelTig5BODTIgPV15Si9+Xrbjk7ogPr8Whz74Ap0u2rQrvq6QEfWM0j6L4OLfz9tdT53wxu5kCIXiqNrltaV4Js/Bfun4gMwskb0VCcgY9Bs7PqtJ6prO4HBdaEWY02G1L4JrxVve04z03GxGsvWjxQkY6BgYOFQVSlkGBbfBsPX7LHrrHMXrgGttXA7+ryzSLVhMddsxt79OGMbtTcgZXLY+IVaEMb50A+LwdBhvZFTUIrV+86b+3p0NYObC+UYVKhAv4uWNnKu8EZ9rBwdxrVzOXujFLlQbF1ToahEQvdTGPdFJvKLfwILFr3b9MGswc9jbI/70adtXzAMg23782DrzoQ2M0lhXmqJ14q3rR/TFmI0lq0fSWdkraJRbC324XNw4RrQZIxtAZfaPu0O9oSN6/5jI5ROty/XgCTmbNOZh95UT5PzsiyKxe5b9dh9a3P4osl5aQpvPPFRMdgf6xBRf13GFCUGt7I3SvHWZTr3qrzvcK7pI8jlGtThBM4Usujbth/m3DYfY3vcj95t+1h9V6qsiVJvw+a14m2rA7nrqPIUrvPXNOqxe/rt5r/HbsoXdCS252xtOWiYjntTTLqz2BM2IWeEYs42XXnoHX3WFN6Ydf4PlPRv8VkW6FTOIOWCEuMrIlzO3njnGDVGT04UxdmXX3wIU3dNQlHt5eYDcqBzeBc83W8hxva4Hwltetn9vlRZE6VOteu14g1Yz5K4QqiEbixnfyShR2J7M6KBN0R5lX3aXey1oeAzwhZRswyAe2/sIEgbuvLQu933GOBKNItPohsxe7blQiFDjQG1udXmRF9so/jZGw8W7Ufarkkorbe8TqgiDG+Nehcj4kY5fS5X+wVfTkapU+16tXi3RqrGcva6YozEXK/9Utmn+cZRGwpxnzkFpXgh5w8L/wULYPv/SjHwhijer+dKPxai78kj5Yga3xZR4zk2p/5zMZLLm1M7yN6Yd3kP0nY+ifLGcovjUUo1NqZuxt1dR3B+1xHO9gt7ZjnAtYmB1E59r16kYwupQnOcua5QKSp9EXcXJqzcfcpmrpkHBsZi3gj7r8+O4PoNR/znIKob9Ta/48nCGHtt4Eo/FqLvufoc2Qtv5EIerYD2rkZkh67Evs550AXpzGXtVO2wceQ7SOl8p1Pn4guut/colQJavVGQZ1eoRTo+J97eSMsHIUIph1wuQ1W9zqvNF7YyK7qySMkR7nZYoVYXconbvTd2sJuYzJPVvGLn83ZlBS1fkwxW92f2xh1ubE7tQXiju5M4rv08ueBjVWvArbD0FVo/CDVaA1RBLJbd09srRRtwnFnRlVwhfL8Fcdm8SzRah0mx7GEvRt4evhSx46zpgM8QNyaIQdgdEci7IQ9TujwBreH67xdTGYN7L9yLCUV/h+Kw5aIie9kb1Q+3g/rRdgjqHAxGZu0w9SS+2l7ggy1a9kepcxm1hsTbQ2w+CDrn0qdKhTOZFe3l+l7fIv7YBF9hkfYeLk/O72qMPOB5+mFvxVPHuqkPnK37AdeUqwBY9qWukd3wxog3cVtsks1Zp0X2xpwqGCquL3bTXWzCtTXFuLamGEwIA2W8CsEJKih7qqBMUCG4pwpv7nV/8OHyIQTLGbuL7qRekGMLEm8P8SR9qlQ4+5CaPrdy9ymbqzhbw0dYpL34fmfOzzU7cjVGngGweHQvr/z9PMVdxzrLsli29x2sP5HRfKDFx2NDuuO9ezbjlpjBDq/vKHtj47F6GBuNaCpshPaMFo2/1aNme6V5jFgOBcoiZShua0RxOxbF7YwoaWtESdsmsCxrN7yRy8kIwK5jWOoFObYg8fYQT9KnSoWzr44xEUpOByIXfKzqBMCZ1dDe+e3NjlyNkfdnJ7O9CJbWg9+0O+JQr9iL9N2Trc4TZOyK6KbZCGZ7IFahdEq47dFyc+rWGBuNaDqnhfZ0IzZ/WIjwEhax5QyS/ydHSNN1sT75/m/mGfqFKD2+qatEQYgW6BqMtLu6mU1LXL8tl1nEnbcVoc0sdsVbp9NhwYIFKCoqQlNTE6ZNm4aePXti3rx5YBgGCQkJyMzMhEzm23lxPSE9uZtbQiMltnYoao3pYV6aY/veuODDRjymb4xN04yj89ubHZmcTu7GyHubvdMTTPVe+8MZc5RNsJwxJzhr0BtQJ8/Fef2ryN9j+d0gY7c/BdsycyYffd1eG8tUMqj6hkDVNwR9esZdH3xYQF3LIK5Kjn92iEHP2iBoCxtRvrca6qsG/ANyAKEwMizKXruII3HXoPpN2xzeODoKkWPUCE5QgWEYu6Lu6tuKGGYWu+K9fft2qNVqrF69GpWVlRg/fjz69OmDjIwMJCUlYcmSJcjNzUVqaiovlfFFvDl9KhemOuts1Blo9rCbHhyugckWfMbcc5lP6pu4zVGOZkfuxsh7o72TD7Qt2rZaq8e7v7+LiuB/A622bQxFAnY8uhV92vZtjgbSCrOvrLNt3Nr0oeoUjIDmn2YAABloSURBVAce6YbkVgv6Ksu1iK2QIbaCQcdyGTpWyDDgRCMA5vrm1C9esTi3eXPqMWqE3XE9eyPX28qw+DYYuynfasARw8xiN1Swrq4OLMsiPDwclZWVePDBB9HU1IS8vDwwDIPdu3fjwIEDyMzMtHsRo9EIg0HwiETJ2H70ChZ+9TsadS1+2CAZXvxrf4wb2InzO2t3nUJxdSM6RqkwO7UX52c9qRfXNXot3sEZMlW4fLT5332W7IC9n45B84KWTq3OL5fLYDC4t91cy/pnfVeAynqdxXGuth2+Zg+uVDeiNZ2iVNj73J1u18Pd8/LRBkIxfM0eFFXXo1a+AxXB663Kg429Ed2UgSC2CxgAp/7sE672dWfbwNPfrnVft3UuE6EyGbK7xKPPCQYV28uhvejcW0PTbSHYEVuHvZ0boeyixJ2922Pbr0UWbQEA6hAFqhpsrxto2ZbOEBTEvZLV7sw7LCwMAFBbW4sZM2YgIyMDq1atMjsEwsLCoNFo7J0CAGAwsH4d550Sp8aC1ATzTKBjlApTh8UhJU5t875bzzKuVDdi4Ze/o65ey9uo7Oga9uzeH/10zlyP+wfEctq8Y22YD0z3y0eMc0qcGkq5tUmuUWfE6u//sNrcd+qwOJuzo6nD4jyqSzGHEBRXN9o9r9hx3ly0NEd0CA9Cr/j9+KlpOdDKtKw09EM73UwEsZb5x2MilOb7aN3XTbNNrr7u7EIlrvmBozY2nad1X7dHvdGI7IpL+HpJEtou6WhR1nRBi5/fv4SKbyrR45xl3ws+3IBxkGEc/tyoFBUYiRBcjTLilwQDfk3Qo7CzkVO4Acu2dAaP4ryLi4sxffp0TJw4EWPHjsXq1avNZXV1dYiMjHS6Iv5My1dvRw+tGK9Ujq5hz1bfsh6mVY2maBMZA4wf4PlqR2dxxVEk1HJlqRMQeUJOQSle3HkS1/AlKkPexnkD8HOL/SyUhpv+FOxYm9+3ZQrjI0WBrYVCtjBtlGHvN3VnU3GufpVbX4UVkSVofPj6+YJkDCIhQ5dTwLDzwRh0WgF59fXyDtUyjP6vDKP/G2R1vl8S9NgyogmVkSzvqTzsindZWRkmTZqEJUuWYOjQoQCAfv36IT8/H0lJScjLy8OQIUN4q0ygIEYqSWfsv846WueN6CWaWLfGVeEUIveJ1AmI3HGWfnO8CJn71uKS8S0rG7bKcDO6yTLA6jtY3dNNHcNx5HKNeaAWKjmXM4Jrsik7soW789xw9R+u9M/lMKC8J/BbzwaoRjdHI63fdx4lNVp0KmcwqFCBQYVyxBdbmjkGFSrAsMAnT0DcaJMNGzagpqYG69evx/r1zXaxhQsXIisrCy+//DLi4+MxapTz2b+IZsSYyTlzjVgfmFFKLZyAtAmIXHHk6Qw6/PvXV5H983Kr86gMg9FO9zQUbHsAQCOAZfdYmj9M+ehNQUhGFvj2+FVBknM5ElyTSc6Zt1RXY/gB7q0UnRkIWqcovhJtxJVoHb4Zaumb6cDKMeBiEA7EahEF/p8pu+K9aNEiLFq0yOr41q1bea9IICGGIDlzDW8QRkdInbmtZT2kiCxxJF5Nhia89starD6cbfXdEEMi2jalQ4Foq7KYPzewaJ1yWayFKPZ8LgxgDu10ZocjV2L4geYkZ66GBNq6vq2QSxMKBqiUGbE7rtn+3iB2qCAhDGIIkjPX8BZhdIS/pLt1B1szQRY6nGzYgg7rrUN0w423Q62dBjna2D2vrQFazJ1h7PlcIlXXZcmZN0h7/diVPPc5BaVo0NkOn+W6vqlvtjZtNegMVoLO90BI4i0RYgiSM9cIZGH0BUzixaIJVYoPURP0mdVn/trjb1iRvBqTtp51OumSrd/ckVDyuVBpTN8YHC2qthnJVKe9Hsvv7NuhuzH8Jpx1oJpwdP3b1ubZ/J4rSbEcQeJNOIU/rTD0FRr0DWjT8WPk69+2KhsaMxab73kd7ULamY+VagqcOm8sh0/D0bJ5PhYqte5HKjmDxlYLCfTs9Ygnsd4OXYlYsWd2McFlb7eRJNFtSLwJh/jTCkNvH4TqdHXIzn8Bm469YVUWpr8bfZTTMSNlgEsz55bY82nYE0o+7OG2+hEXLU01Yrwd2jMNxUYordqjZXZNk1Cb/h8boeR0lDpK7uYKJN6EQ7wxo5o7eOsgVKurxfKfluCd39+yKvt738ex9PYsRCnVNr5pia2Zc5CMQUiQDBqtwemtvdxJPeAMrsxuxY544hr4TJsxmMQ687s/sCb3NBp0RnNuoJbROYD9QSlS6dneny0h8SYcIqYjS0i8aRDSNNVg6cHF2HLiHauyx/tNQubtLyAi2LUFcEKaGFwJb235dmNabTymb4zT/UWKiCdXTEa28hg5i710ta5C4k04xJdXGLZE6kGoWluFJQcW4KOT1qG2k/pPxqKhyxAeFO7RNYQyMTjrOLS1VN30dsPVj6JUCoQEyXkfcFwxkblqMnKXGo69Ut2BxJtwiC/EgzuDFINQZWMFFu2fh/879bFVWdqAdMxLWoywoDDBru8O9kTPkRjae7vh6kez7+7B+4DDZSI7WlTNuVerqyYjd+Czr5F4Ew7xlXhwR4g1CJU3lGPBvufwxenPretw8wzMTVyIEIX1hgPegCO/gKPf3N7bjZj9iGsQcWevVlf3vQSaF+kwDGORM1/U3CYEYcIf4sGFFI9r9dcwb99sfH3mS6uymYNmY/atc6FSqDy+jtB46hdw9HYjVj9ydrbszL0Ni29jFY+uYIAwpQLVjXqb0SYtt0+TZCcdgvA3+BSP0vpSPL/3WeSc+8aqbNatz2PZ3ZloqHXfuSUFnvoFXHm7ETJs05XZsr0d4k35XlrzVycza47pGyNYamASb4JwgeLaK5izNwM7L+ywKnv+tgWYMWgWguXBAAClQokGSJ/P2xU89Qu0frtpGW3SEqHDNu1tZN0aezvEc+WyP3C20uM6egqJN0E44LLmEmbvmYEfL+ValS1MykT6zTMQJLfO5eyL8OEXcCa3vdBhm7ZMZF3UShy+VGP12WHxbTjrxEWJRovEtXmIVCnAsqzTcfR8QuJNEDa4WHMBz+55Bvsu77EqWzJ0OaYOnA6FzP8eH7GcimKEbdrKmmgL0yzaVackC1gknxJ70Zf/9T6CcJNz1WeR8eN0/HTlgFXZC8NWYPJN0yCX8bdCzlsRw6koRdimowHDXv5vZ2n59rBy9ylBd6Ai8SYCmrNVp/HMD9NwuMR6VpadvBpP9p8MGWO9jybhGXyFbbri9HQ0YPCVd6RUo8XK3acs7OVGFua/+RJwEm8i4CisPIVnctPwy9UjVmUvpbyCx298kgRbYPgwz7jq9HS0BJ6PmTfQbE7hcnR+cayExJsgXKGg/ASezk3D/8qOWpW9cue/MbHvY7zmnSAc40qubVsi76rTk2vAAIAVOwt5zfjHBWUVJAgn+L3sf5i+ewoKKo5blb1+9xt4pPdEEmwvx97s2h2np60Bw53cJaY0saZoE2eTVVE+b4Lg4Ni135C+ezJOVVpvsbV+xJt4IOFhEmwfIaegFEtz/rCarZpm13w5PV2NcJEx1/fYNMG1c05rxg+Idela9iDxJnyeX0uPYOrup3Cu+qxV2Zsj38W4HuNJsH0M04yby8xQqtFi2T29eXF6upq7hGuHHHsmEYo2IYg/OVySj2m7/oWLmgsWxxUyBTamvoOxPf4qUc0IPnC0YCYmQslbTLotR6aCad6OzRa2tpGzJ9yFy0fT8ngisDl05SDSdk1Ccd0Vi+MquQobR76DMd3vlahmBN/YM2XwnZ2v5SBg2taMS7gBoEFnQOLaPIvBQow9K1tD4k14NfuL8pC2cxKuNVgmBwoLCsem1M1I7TZaopoRQsJlypAxwIKRCeZ9JPnKj2L6vDP5UEyrKlteT4w9K1tD4k14HXsv/YgpO59ApdYy+Y9aqcaG1M24u+sIiWpGiAVXTLZJuAH+86O4ktuk9fVi7eyBKRQk3oRX8MPFXZi880lomiwTB0WHRGND6makdL5TmooRkuCMPZvv/Cjufq9Eo8UDA2Px7fGrou42ReJNSMbO8zmYsvNJ1OstnTkxobHYmLoZt99wh0Q1I7wBR4t4+M6PYi/qRMYASoUMDTrbM/Nvj1/FvTd24NxiTQhIvAlR+fbs15iy8wnojDqL453Du+CN1LeR1HGIRDUjfA2+t7WzlwPcyAI6vRFBMsutzUw06o04cLbSKv5bSEi8CcHZfvoLTN75BFhYdvq4yG7YkPo2BsfcJlHNCF+G7/S1raNOWqNngchgGXQcqyn5TGfrDAzLsoKv6NfpDILEOXorQm175CuwLIvvr3yNx7/6h1VZT3UC1o94Ezd3GCRBzcQl0PsB4LttkLg2D7aEkQG3ecW0d2XrwWTC0O5ut0H79hGcZTTzJniBZVn836mP8XRumlVZn7Z98Z+/bMJN7QdKUDOCcB0ugY5UKVDfpLc6rlLIMCy+jc3QxbBQJVLi1LzXkcSbcBuWZfHRya3I+HG6VdmADgPx2p1v4Mbo/hLUjAhU+NrU2Jb9O0jGoE6rt1rAE6VSYPbdPThDF9fuOoWUfyW6dT/2IPEmXIJlWWw58S6e2zvTquzm9rdg3V82onfbPj77ukz4LkIs2mk5ENQ36W1mDwwJkmNM3xhkfmedDA0ArlQ3YuymfN6jT5wS76NHj2LNmjXYsmULLly4gHnz5oFhGCQkJCAzMxMyGSWu92eMrBHv/P4W5u97zqpscMxtWHf3BvRskyBBzQjiOnwv2mkdqpjIkTnQ5Ki0F2ooxP6WDlX3zTffxKJFi6DVNlcqOzsbGRkZ+PDDD8GyLHJzrXfUJnwfI2vEpqPr0WF9JGLfUFsId1LHoTj0919xNb0GOQ/kknATXoHQmxpzxY9HKJv3NU1P7gaVgltSTQMJXzgU765du2LdunXmv48fP47ExGb7TUpKCg4ePMhbZQhpMRgNWP/bOrNgLzowz1x2xw0p+PnvR3E1vQZfj/8e8VE9JKwpQVjDJa6OFu3kFJRi7KZ8JK7Nw9hN+cgpKLX5ufTkblDYSDTVoDMip6AUY/rGYMHIBLtL4vkMJ3RoNhk1ahQuX75s/ptlWXNu5LCwMGg0GocXkcsZqNWhHlTTt5DLZT5zv3qjHi8fWotFexZalaV2T8X6ezYgLirO5fP6UhsIBbWBuG0wZ1RvLPzqdzS2WAWpCpJhzqjenHXYfvQKVuwqNH+nRKPFil3NESLjBnay+OyEod3xyp6zqKy3XGCmM7LYcOACJgztbv5v+Jo9uFLdaHW9jlEq3trDZYdlS/t2XV0dIiMjHX7HYGADynnl7c46nUGHdb++gpU/Z1mVjeg6EmvufA2dwm9oPsDCrXvx9jYQA2oDcdsgJU6NBakJVtEmKXFqzjqs/v4PC7EHgEadEau//8NmeF9VK+E2UVzdaHGNqcPibK7+nDoszqX24DXOu1+/fsjPz0dSUhLy8vIwZAgtZ/YFmgxNeOXIaqz97yqrstHd7sFLw19BbFhHCWpGEPzh7KbGJly1kzubT2VM3xh8/b9iHL50PdHaTR3DxY82acncuXOxePFivPzyy4iPj8eoUaN4qwzBL1qDFmsPr8Krv6yxKrs3fhxWpqxFTKhwiXMIwlP4itvmwtXkVs7mU1m5+5SFcAPA4Us1WLn7FG9bodHyeAGQ8nW5Ud+Ilw6vwL9/fdWq7P6ef8OK5DWIDokWvB5kMqA2ADxrg9Zx24B1Tm9PcecazgwoSS/nce6skz8rxen60fJ4P6deV4/sn5dj49H/WJU9kPAwXkxehbaqdhLUjCDch++4bVu4k9zKGdOMGDvrkHj7KLW6Wqw4tAxv/W+jVdmjff6OF25fAbWqjQQ1Iwh+EDpu24SrdnJnEGNPSxJvH6K2SYNlPy3Be8fftir7R99/YuntWYhURklQM4LgH743WxCT8QNi8fnREpvH+YLE28up0VZj6cFF2FrwnlXZP298CkuGLkNEsONwTYLwNfjebEFMTE7JL46VwMg2z7jHD4jlzVkJkHh7JVWNlVhycAE+PvmBVdm/bkrDgiGZCA8Kl6BmBCEefG+2ICS2nJgDb4gyb4vWIVyJgTfw+1ZM0SYC4I6HvaKxHAv3zcXnhZ9alaUNnI75iYsRGuQ7q/Uo0oLaAAiMNrAVsRIkY8CyrEX6WHciZSjaxEspayjDgn3P4cvT26zKpt88E88nLkCIIkSCmhEE4Sy2omK49rnkM1KGxFtkrtZfxby82fjm7FdWZRmDnsOsW5+HSqGSoGYEQbiDK9EvoiamIjyntK4Ec/ZmYMf576zKZt86F88OnoNgebAENSMIwlPs5fG29Vm+IPEWiCu1RXhuz0zsvrjTqmxu4kLMuGUWguRBEtSMIAg+4doyzZbNm89IGRJvHrmsuYRZe57Bnks/WJUtGrIU6TfPgEJGTU4Q/gRXVIytY3xGylC0iYdcqDmPZ398GvuLrLdIyhyahbSB6QEp2IEQZeAIagNqA8CzNqBoE545W30GM39IR37xT1ZlWcNWYnbys9DU8LuElyAIoiUk3k5yurIQz/wwFUdKD1uVZSevwZP9/wUZ07xRhVwmF7t6BEF4GSt3n6IVllLxR8VJPJObht+u/WpVtnr4q3is3xNmwSYIgjCxcvcpi9wmRhbmv/kScBLvVhSUn8D03Cn4veyYVdmrd/0HE/r8w7yHJ0EQhC2+OGadlMp0nMSbR/5XdgzTd0/GyYoCq7J1d2/Aw70nkGATBOE0lM9bQH67+gvSd0/G6apCq7INqW9jfM8HSbAJgnALyufNM0dKD2Pqrqdwoea8VdlbI9/DuJ7jxa8UQRB+B+Xz5oGfi/MxddckXK69ZHE8SBaEjanv4L4e4ySqGUEQ/ooY+bz9cpHOwaL9SNs1CaX1liNfiCIEG1Pfweju9wh6fVqYQG0AUBsA1AYALdJxyL7Le5G260mUNZRZHI8IjsSm1M34S9xIiWpGEATBPz4t3j9ezEXaridRpa2yON5G2QYbR76DO7vcLVHNCIIghMXnxHv3he8xeeeTqNPVWhyPDmmPjambkdx5uEQ1IwiCEA+fEO8d577DlJ1PoNHQaHG8Y1gnbEh9G0M7DZOoZgRBENLg1eJtMBrQcUMbi2NdIrrijRFvI7FjkkS1IgiCkB6vFm+5TI6He0/Az8WH8EbqWxgcc5vUVSIIgvAKvFq8AeDff9kodRUIgiC8DkqJRxAE4YOQeBMEQfggJN4EQRA+CIk3QRCED0LiTRAE4YOQeBMEQfggJN4EQRA+CIk3QRCEDyJKPm+CIAiCX2jmTRAE4YOQeBMEQfggJN4EQRA+CIk3QRCED0LiTRAE4YOQeBMEQfggJN4EQRA+iNdvxuDt6HQ6LFiwAEVFRWhqasK0adPQs2dPzJs3DwzDICEhAZmZmZDJ/H+cLC8vx9/+9jds3rwZCoUi4Npg48aN+OGHH6DT6TBhwgQkJiYGVBvodDrMmzcPRUVFkMlkWL58eUD1g6NHj2LNmjXYsmULLly4YPO+P/30U3z88cdQKBSYNm0a7rrrLvcvyBIe8dlnn7FZWVksy7JsRUUFO3z4cDYtLY09dOgQy7Isu3jxYnbnzp1SVlEUmpqa2PT0dHbkyJHs6dOnA64NDh06xKalpbEGg4Gtra1lX3/99YBrg127drEzZsxgWZZl9+/fzz799NMB0wabNm1i77vvPvahhx5iWZa1ed9Xr15l77vvPlar1bI1NTXmf7uLfw6BIjJ69GjMnDnT/LdcLsfx48eRmJgIAEhJScHBgwelqp5orFq1Co8++ig6dOgAAAHXBvv370evXr0wffp0TJ06FXfeeWfAtUH37t1hMBhgNBpRW1sLhUIRMG3QtWtXrFu3zvy3rfs+duwYbrnlFgQHByMiIgJdu3bFyZMn3b4mibeHhIWFITw8HLW1tZgxYwYyMjLAsiwYhjGXazQaiWspLNu2bUPbtm2RnJxsPhZobVBZWYnff/8dr732GpYtW4bnnnsu4NogNDQURUVFGDNmDBYvXozHHnssYNpg1KhRUCiuW6Ft3XdtbS0iIiLMnwkLC0Ntba3b1ySbNw8UFxdj+vTpmDhxIsaOHYvVq1eby+rq6hAZGSlh7YTn888/B8Mw+Omnn1BQUIC5c+eioqLCXB4IbaBWqxEfH4/g4GDEx8dDqVSipKTEXB4IbfDuu+/ijjvuwOzZs1FcXIx//vOf0Ol05vJAaAMTLe36pvsODw9HXV2dxfGWYu7yNTyqIYGysjJMmjQJc+bMwYMPPggA6NevH/Lz8wEAeXl5uPXWW6WsouB88MEH2Lp1K7Zs2YK+ffti1apVSElJCag2GDx4MPbt2weWZVFaWoqGhgYMHTo0oNogMjLSLEZRUVHQ6/UB9yyYsHXfAwYMwJEjR6DVaqHRaHDmzBn06tXL7WtQVkEPycrKQk5ODuLj483HFi5ciKysLOh0OsTHxyMrKwtyuVzCWorHY489hqVLl0Imk2Hx4sUB1QYvvfQS8vPzwbIsnn32WXTu3Dmg2qCurg4LFizAtWvXoNPp8Pjjj6N///4B0waXL1/GrFmz8Omnn+LcuXM27/vTTz/FJ598ApZlkZaWhlGjRrl9PRJvgiAIH4TMJgRBED4IiTdBEIQPQuJNEAThg5B4EwRB+CAk3gRBED4IiTdBEIQPQuJNEAThg/w/7pYSxCODb5kAAAAASUVORK5CYII=
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_hide</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">animation</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_tight_layout</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">LinReg2</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">LinReg2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sk</span> <span class="o">=</span> <span class="n">skLinReg</span><span class="p">()</span>
<span class="n">sk</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">sk</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="s1">&#39;m-&#39;</span><span class="p">)</span>
<span class="n">line</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_test</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X_test</span><span class="o">.</span><span class="n">dtype</span><span class="p">)))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">LinReg2</span><span class="o">.</span><span class="n">Theta</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="s1">&#39;Sklearns&#39;</span><span class="p">,</span> <span class="s1">&#39;Our&#39;</span><span class="p">))</span>

<span class="n">Writer</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">writers</span><span class="p">[</span><span class="s1">&#39;pillow&#39;</span><span class="p">]</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">Writer</span><span class="p">(</span><span class="n">fps</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">artist</span><span class="o">=</span><span class="s1">&#39;Me&#39;</span><span class="p">),</span> <span class="n">bitrate</span><span class="o">=</span><span class="mi">1800</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">init</span><span class="p">():</span>
    <span class="n">line</span><span class="o">.</span><span class="n">set_data</span><span class="p">([],</span> <span class="p">[])</span>
    <span class="k">return</span> <span class="n">line</span><span class="p">,</span>

<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
    <span class="n">LinReg2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
    <span class="n">line</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">LinReg2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">line</span><span class="p">,</span>

<span class="n">anim</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="n">init_func</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
                               <span class="n">frames</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">repeat_delay</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">anim</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;gif/linreg.gif&#39;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">writer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/gif/linreg.gif" alt="" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, I had said that we will see two algorithm to find values for theta. The first one was gradient descent. The second is called the normal equation. This equation is possible because linear regression is a quite simple idea, so smart people have found a formula that makes the learning process unnecessary and just gives you the correct answer. If you interested in the proof; do go online, I will not do it here. Anyways, here is the equation:

$$(X' \cdot X)^{-1} \cdot X' \cdot y$$

Obviously this equation will not work for every situation. Since you need to invert a matrix you may end up with matricees of data where it is not possible to do so.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">C</span>
<span class="n">ode</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">def fit(self, X, y, lamb=0, add_intercept=True, iters=100, lr=3e-8):</span>
<span class="s1">    &quot;&quot;&quot;Fits the training data using normal equation&quot;&quot;&quot;</span>
<span class="s1">    if add_intercept:</span>
<span class="s1">        X = np.column_stack((np.ones((X.shape[0], 1), dtype=X.dtype), X))</span>
<span class="s1">    n, p = X.shape</span>
<span class="s1">    self.X = X</span>
<span class="s1">    self.y = np.reshape(y, (len(y), 1))</span>
<span class="s1">    self.Theta = np.linalg.inv(self.X.T @ self.X) @ self.X.T @ self.y</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s1">&#39;py&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<style>.output_html .hll { background-color: #ffffcc }
.output_html  { background: #f8f8f8; }
.output_html .c { color: #408080; font-style: italic } /* Comment */
.output_html .err { border: 1px solid #FF0000 } /* Error */
.output_html .k { color: #008000; font-weight: bold } /* Keyword */
.output_html .o { color: #666666 } /* Operator */
.output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.output_html .cp { color: #BC7A00 } /* Comment.Preproc */
.output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */
.output_html .cs { color: #408080; font-style: italic } /* Comment.Special */
.output_html .gd { color: #A00000 } /* Generic.Deleted */
.output_html .ge { font-style: italic } /* Generic.Emph */
.output_html .gr { color: #FF0000 } /* Generic.Error */
.output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.output_html .gi { color: #00A000 } /* Generic.Inserted */
.output_html .go { color: #888888 } /* Generic.Output */
.output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.output_html .gs { font-weight: bold } /* Generic.Strong */
.output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.output_html .gt { color: #0044DD } /* Generic.Traceback */
.output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.output_html .kp { color: #008000 } /* Keyword.Pseudo */
.output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.output_html .kt { color: #B00040 } /* Keyword.Type */
.output_html .m { color: #666666 } /* Literal.Number */
.output_html .s { color: #BA2121 } /* Literal.String */
.output_html .na { color: #7D9029 } /* Name.Attribute */
.output_html .nb { color: #008000 } /* Name.Builtin */
.output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.output_html .no { color: #880000 } /* Name.Constant */
.output_html .nd { color: #AA22FF } /* Name.Decorator */
.output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */
.output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.output_html .nf { color: #0000FF } /* Name.Function */
.output_html .nl { color: #A0A000 } /* Name.Label */
.output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */
.output_html .nv { color: #19177C } /* Name.Variable */
.output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.output_html .w { color: #bbbbbb } /* Text.Whitespace */
.output_html .mb { color: #666666 } /* Literal.Number.Bin */
.output_html .mf { color: #666666 } /* Literal.Number.Float */
.output_html .mh { color: #666666 } /* Literal.Number.Hex */
.output_html .mi { color: #666666 } /* Literal.Number.Integer */
.output_html .mo { color: #666666 } /* Literal.Number.Oct */
.output_html .sa { color: #BA2121 } /* Literal.String.Affix */
.output_html .sb { color: #BA2121 } /* Literal.String.Backtick */
.output_html .sc { color: #BA2121 } /* Literal.String.Char */
.output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */
.output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.output_html .s2 { color: #BA2121 } /* Literal.String.Double */
.output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */
.output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.output_html .sx { color: #008000 } /* Literal.String.Other */
.output_html .sr { color: #BB6688 } /* Literal.String.Regex */
.output_html .s1 { color: #BA2121 } /* Literal.String.Single */
.output_html .ss { color: #19177C } /* Literal.String.Symbol */
.output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */
.output_html .fm { color: #0000FF } /* Name.Function.Magic */
.output_html .vc { color: #19177C } /* Name.Variable.Class */
.output_html .vg { color: #19177C } /* Name.Variable.Global */
.output_html .vi { color: #19177C } /* Name.Variable.Instance */
.output_html .vm { color: #19177C } /* Name.Variable.Magic */
.output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">add_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-8</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fits the training data using normal equation&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>
</pre></div>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see using this equation we ended up with the same error, so with the same theta (weight) that scikit-learn has found.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Linear regression algorithm&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">add_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-8</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fits the training data using normal equation&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">add_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Makes predictions on the given data&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span>
    
    <span class="k">def</span> <span class="nf">_gradient_descent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iters</span><span class="p">,</span> <span class="n">loss_prime</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gradient descent algorithm&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">loss_prime</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span><span class="o">.</span><span class="n">T</span>
            <span class="k">if</span> <span class="n">loss</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Theta</span><span class="p">))</span>
                
<span class="n">LinReg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">LinReg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Our: &#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">LinReg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">),</span>
      <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Sklearns: &#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Our:  64.45241584915267 
Sklearns:  64.45241584915276
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="posterrieri/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/machine%20learning/numpy/2020/10/26/Learn-Linear-Regression-by-Implementing-In-NumPy.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/posterrieri" title="posterrieri"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
